2019,Computational sustainability: computing for a better world and a sustainable future.,"Computer and information scientists join forces with other fields to help solve societal and environmental challenges facing humanity, in pursuit of a sustainable future."
2019,Locally-biased spectral approximation for community detection.,"We propose a Locally-Biased Spectral Approximation (LBSA) approach for identifying all latent members of a local community from very few seed members. To reduce the computation complexity, we first apply a fast random walk, personalized PageRank and heat kernel diffusion to sample a comparatively small subgraph covering almost all potential community members around the seeds. Then starting from a normalized indicator vector of the seeds and by a few steps of either Lanczos iteration or power iteration on the sampled subgraph, a local eigenvector is gained for approximating the eigenvector of the transition matrix with the largest eigenvalue. Elements of this local eigenvector is a relaxed indicator for the affiliation probability of the corresponding nodes to the target community. We conduct extensive experiments on real-world datasets in various domains as well as synthetic datasets. Results show that the proposed method outperforms state-of-the-art local community detection algorithms. To the best of our knowledge, this is the first work to adapt the Lanczos method for local community detection, which is natural and potentially effective. Also, we did the first attempt of using heat kernel as a sampling method instead of detecting communities directly, which is proved empirically to be very efficient and effective.
"
2019,Krylov Subspace Approximation for Local Community Detection in Large Networks.,"Community detection is an important information mining task to uncover modular structures in large networks. For increasingly common large network datasets, global community detection is prohibitively expensive, and attention has shifted to methods that mine local communities,  i.e., identifying all latent members of a particular community from a few labeled seed members. To address such semi-supervised mining task, we systematically develop a local spectral (LOSP) subspace-based community detection method, called LOSP. We define a family of LOSP subspaces based on Krylov subspaces, and seek a sparse indicator for the target community via an ‚Ñì1 norm minimization over the Krylov subspace. Variants of LOSP depend on type of random walks with different diffusion speeds, type of random walks, dimension of the LOSP subspace, and step of diffusions. The effectiveness of the proposed LOSP approach is theoretically analyzed based on Rayleigh quotients, and it is experimentally verified on a wide variety of real-world networks across social, production, and biological domains, as well as on an extensive set of synthetic LFR benchmark datasets."
2019,A new anchor word selection method for the separable topic discovery.,"Separable nonnegative matrix factorization (SNMF) is an important method for topic modeling, where ìseparableî assumes every topic contains at least one anchor word, defined as a word that has non?zero probability only on that topic. SNMF focuses on the word co?occurrence patterns to reveal topics by two steps: anchor word selection and topic recovery. The quality of the anchor words strongly influences the quality of the extracted topics. Existing anchor word selection algorithm is to greedily find an approximate convex hull in a high?dimensional word co?occurrence space. In this work, we propose a new method for the anchor word selection by associating the word co?occurrence probability with the words similarity and assuming that the most different words on semantic are potential candidates for the anchor words. Therefore, if the similarity of a word?pair is very low, the two words are very likely to be the anchor words. According to the statistical information of text corpora, we can get the similarity of all word?pairs. We build the word similarity graph where the nodes correspond to words and weights on edges stand for the word?pair similarity. Following this way, we design a greedy method to find a minimum edge?weight anchor clique of a given size in the graph for the anchor word selection. Extensive experiments on real?world corpus demonstrate the effectiveness of the proposed anchor word selection method that outperforms the common convex hull?based methods on the revealed topic quality. Meanwhile, our method is much faster than typical SNMF?based method.
"
2019,Adaptive Wavelet Clustering for Highly Noisy Data.,"Abstract:
In this paper we make progress on the unsupervised task of mining arbitrarily shaped clusters in highly noisy datasets, which is a task present in many real-world applications. Based on the fundamental work that first applies a wavelet transform to data clustering, we propose an adaptive clustering algorithm, denoted as AdaWave, which exhibits favorable characteristics for clustering. By a self-adaptive thresholding technique, AdaWave is parameter free and can handle data in various situations. It is deterministic, fast in linear time, order-insensitive, shape-insensitive, robust to highly noisy data, and requires no pre-knowledge on data models. Moreover, AdaWave inherits the ability from the wavelet transform to cluster data in different resolutions. We adopt the ""grid labeling"" data structure to drastically reduce the memory consumption of the wavelet transform so that AdaWave can be used for relatively high dimensional data. Experiments on synthetic as well as natural datasets demonstrate the effectiveness and efficiency of our proposed method."
2019,Improving the Generalization of Adversarial Training with Domain Adaptation.,"By injecting adversarial examples into training data, adversarial training is promising for improving the robustness of deep learning models. However, most existing adversarial training approaches are based on a specific type of adversarial attack. It may not provide sufficiently representative samples from the adversarial domain, leading to a weak generalization ability on adversarial examples from other attacks. Moreover, during the adversarial training, adversarial perturbations on inputs are usually crafted by fast single-step adversaries so as to scale to large datasets. This work is mainly focused on the adversarial training yet efficient FGSM adversary. In this scenario, it is difficult to train a model with great generalization due to the lack of representative adversarial samples, aka the samples are unable to accurately reflect the adversarial domain. To alleviate this problem, we propose a novel Adversarial Training with Domain Adaptation (ATDA) method. Our intuition is to regard the adversarial training on FGSM adversary as a domain adaption task with limited number of target domain samples. The main idea is to learn a representation that is semantically meaningful and domain invariant on the clean domain as well as the adversarial domain. Empirical evaluations on Fashion-MNIST, SVHN, CIFAR-10 and CIFAR-100 demonstrate that ATDA can greatly improve the generalization of adversarial training and the smoothness of the learned models, and outperforms state-of-the-art methods on standard benchmark datasets. To show the transfer ability of our method, we also extend ATDA to the adversarial training on iterative attacks such as PGD-Adversial Training (PAT) and the defense performance is improved considerably."
2018,Hidden community detection in social networks.,"This paper introduces a new graph-theoretical concept of hidden community for analysing complex networks, which contain both stronger or dominant communities and weak communities. The weak communities are termed as being with the hidden community structure if most of its members also belong to the stronger communities. We propose a meta-approach, namely HICODE (HIdden COmmunity DEtection), for identifying the hidden community structure as well as enhancing the detection of the dominant community structure. Extensive experiments on real-world networks are carried out and the obtained results demonstrate that HICODE outperforms several state-of-the-art community detection methods in terms of uncovering both the dominant and the hidden structure. Due to the difficulty of labeling all ground truth communities in real-world datasets, HICODE provides a promising technique to pinpoint the existing latent communities and uncover communities for which there is no ground truth. Our finding in this work is significant to detect hidden communities in complex social networks."
2018,Neighbourhood-preserving dimension reduction via localised multidimensional scaling.,"When high-dimensional data has an intrinsic lower-dimensional manifold structure, one can incorporate such structure knowledge into dimension reduction and design algorithms for special purposes, e.g., preserving the local neighbourhood or uncovering the global structure of data. Based on such assumption, we propose a neighbourhood-preserving dimension reduction algorithm, Localised Multidimensional Scaling with BFS (LMB), for generating low dimensional representation of data that has a latent manifold structure. LMB applies the Multidimensional Scaling (MDS) on the local neighbourhood of data and stitches the reduced neighbourhoods together to form a global reduction. By analysing the local structure of data, LMB can automatically find a well-fit space for reduction. We thoroughly compare the performance of LMB with other state-of-the-art linear or nonlinear algorithms on both synthetic data and real data. Numerical experiments show that LMB efficiently preserves the neighbourhood while uncovering the embedded structure of data. LMB also has a low complexity of  for a n-item data set."
2018,Local Spectral Clustering for Overlapping Community Detection.,"Large graphs arise in a number of contexts and understanding their structure and extracting information from them is an important research area. Early algorithms for mining communities have focused on global graph structure, and often run in time proportional to the size of the entire graph. As we explore networks with millions of vertices and find communities of size in the hundreds, it becomes important to shift our attention from macroscopic structure to microscopic structure in large networks. A growing body of work has been adopting local expansion methods in order to identify communities from a few exemplary seed members.
In this article, we propose a novel approach for finding overlapping communities called Lemon (Local Expansion via Minimum One Norm). Provided with a few known seeds, the algorithm finds the community by performing a local spectral diffusion. The core idea of Lemon is to use short random walks to approximate an invariant subspace near a seed set, which we refer to as local spectra. Local spectra can be viewed as the low-dimensional embedding that captures the nodes‚Äô closeness in the local network structure. We show that Lemon‚Äôs performance in detecting communities is competitive with state-of-the-art methods. Moreover, the running time scales with the size of the community rather than that of the entire graph. The algorithm is easy to implement and is highly parallelizable. We further provide theoretical analysis of the local spectral properties, bounding the measure of tightness of extracted community using the eigenvalues of graph Laplacian.
We thoroughly evaluate our approach using both synthetic and real-world datasets across different domains, and analyze the empirical variations when applying our method to inherently different networks in practice. In addition, the heuristics on how the seed set quality and quantity would affect the performance are provided."
2018,Curvature-based Comparison of Two Neural Networks.,"Abstract:
In this paper we show the similarities and differences of two deep neural networks by comparing the manifolds composed of activation vectors in each fully connected layer of them. The main contribution of this paper includes (1) a new data generating algorithm which is crucial for determining the dimension of manifolds; (2) a systematic strategy to compare manifolds. Especially, we take Riemann curvature and sectional curvature as part of criterion, which can reflect the intrinsic geometric properties of manifolds. Some interesting results and phenomenon are given, which help in specifying the similarities and differences between the features extracted by two networks and demystifying the intrinsic mechanism of deep neural networks."
2018,Towards Understanding Learning Representations: To What Extent Do Different Neural Networks Learn the Same Representation.,"It is widely believed that learning good representations is one of the main reasons for the success of deep neural networks. Although highly intuitive, there is a lack of theory and systematic approach quantitatively characterizing what representations do deep neural networks learn. In this work, we move a tiny step towards a theory and better understanding of the representations. Specifically, we study a simpler problem: How similar are the representations learned by two networks with identical architecture but trained from different initializations. We develop a rigorous theory based on the neuron activation subspace match model. The theory gives a complete characterization of the structure of neuron activation subspace matches, where the core concepts are maximum match and simple match which describe the overall and the finest similarity between sets of neurons in two networks respectively. We also propose efficient algorithms to find the maximum match and simple matches. Finally, we conduct extensive experiments using our algorithms. Experimental results suggest that, surprisingly, representations learned by the same convolutional layers of networks trained from different initializations are not as similar as prevalently expected, at least in terms of subspace match."
2017,Computer Science in the Information Age.,"For fifty years, computer science was focused on making computers useful. The emphasis was on algorithms, programming languages, and operating systems. Today the focus has changed to applications. Some of the drivers are the amount of computing power available, the quantities of data, and the internet. The impact on computer science created an interest in applications and interdisciplinary research. In this article we will review some of the recent work in clustering in social networks, learning theory, the size of data, and the digitalization of records and the need for privacy in computer systems."
2017,Stacked Generative Adversarial Networks.,"Abstract:
In this paper, we propose a novel generative model named Stacked Generative Adversarial Networks (SGAN), which is trained to invert the hierarchical representations of a bottom-up discriminative network. Our model consists of a top-down stack of GANs, each learned to generate lower-level representations conditioned on higher-level representations. A representation discriminator is introduced at each feature hierarchy to encourage the representation manifold of the generator to align with that of the bottom-up discriminative network, leveraging the powerful discriminative representations to guide the generative model. In addition, we introduce a conditional loss that encourages the use of conditional information from the layer above, and a novel entropy loss that maximizes a variational lower bound on the conditional entropy of generator outputs. We first train each stack independently, and then train the whole model end-to-end. Unlike the original GAN that uses a single noise vector to represent all the variations, our SGAN decomposes variations into multiple levels and gradually resolves uncertainties in the top-down generative process. Based on visual inspection, Inception scores and visual Turing test, we demonstrate that SGAN is able to generate images of much higher quality than GANs without stacking."
2017,"Snapshot Ensembles: Train 1, Get M for Free.","Ensembles of neural networks are known to be much more robust and accurate than individual networks. However, training multiple deep networks for model averaging is computationally expensive. In this paper, we propose a method to obtain the seemingly contradictory goal of ensembling multiple neural networks at no additional training cost. We achieve this goal by training a single neural network, converging to several local minima along its optimization path and saving the model parameters.  To obtain repeated rapid convergence, we leverage recent work on cyclic learning rate schedules. The resulting technique, which we refer to as Snapshot Ensembling, is simple, yet surprisingly effective.  We show in a series of experiments that our approach is compatible with diverse network architectures and learning tasks. It consistently yields  lower error rates than state-of-the-art single models at no additional training cost, and compares favorably with traditional network ensembles. On CIFAR-10 and CIFAR-100 our DenseNet Snapshot Ensembles obtain error rates of 3.4% and 17.4% respectively."
2017,Learning Latent Topics from the Word Co-occurrence Network.,"Abstract
Topic modeling is widely used to uncover the latent thematic structure in corpora. Based on the separability assumption, the spectral method focuses on the word co-occurrence patterns at the document-level and it includes two steps: anchor selection and topic recovery. Biterm Topic Model (BTM) utilizes the word co-occurrence patterns in the whole corpus. Inspired by the word-pair pattern in BTM, we build a Word Co-occurrence Network (WCN) where nodes correspond to words and weights of edges stand for the empirical co-occurrence probability of word pairs. We exploit existing methods to deal with the word co-occurrence network for anchor selection. We find a K-clique in the unweighted complementary graph, or the maximum edge-weight clique in the weighted complementary graph for the anchor word selection. Experiments on real-world corpora evaluated on topic quality and interpretability demonstrate the effectiveness of the proposed approach."
2017,Deep Compression on Convolutional Neural Network for Artistic Style Transfer.,"Abstract
Deep artistic style transfer is popular yet costly as it is computationally expensive to generate artistic images using deep neural networks. We first ignore the network and only try an optimization method to generate artistic pictures, but the variation is limited. Then we speed up the style transfer by deep compression on the CNN layers of VGG. We simply remove inner ReLU functions within each convolutional block, such that each block containing two to three convolutional operation layers with ReLU in between collapses to a fully connected layer followed by a ReLU and a pooling layer. We use activation vectors in the modified network to morph the generated image. Experiments show that using the same loss function of Gatys et al. for style transfer the compressed neural network is competitive to the original VGG but is 2 to 3 times faster. The deep compression on convolutional neural networks shows alternative ways of generating artistic pictures."
2017,Local Lanczos Spectral Approximation for Community Detection.,"Abstract
We propose a novel approach called the Local Lanczos Spectral Approximation (LLSA) for identifying all latent members of a local community from very few seed members. To reduce the computation complexity, we first apply a fast heat kernel diffusing to sample a comparatively small subgraph covering almost all possible community members around the seeds. Then starting from a normalized indicator vector of the seeds and by a few steps of Lanczos iteration on the sampled subgraph, a local eigenvector is gained for approximating the eigenvector of the transition matrix with the largest eigenvalue. Elements of this local eigenvector is a relaxed indicator for the affiliation probability of the corresponding nodes to the target community. We conduct extensive experiments on real-world datasets in various domains as well as synthetic datasets. Results show that the proposed method outperforms state-of-the-art local community detection algorithms. To the best of our knowledge, this is the first work to adapt the Lanczos method for local community detection, which is natural and potentially effective. Also, we did the first attempt of using heat kernel as a sampling method instead of detecting communities directly, which is proved empirically to be very efficient and effective."
2016,Nonlinear Dimension Reduction by Local Multidimensional Scaling.,"Abstract
We propose a neighbourhood-preserving method called LMB for generating a low-dimensional representation of the data points scattered on a nonlinear manifold embedded in high-dimensional Euclidean space. Starting from an exemplary data point, LMB locally applies the classical Multidimensional Scaling (MDS) algorithm on small patches of the manifold and iteratively spreads the dimension reduction process. Differs to most dimension reduction methods, LMB does not require an input for the reduced dimension, as LMB could determine a well-fit dimension for reduction in terms of the pairwise distances of the data points. We thoroughly compare the performance of LMB with state-of-the-art linear and nonlinear dimension reduction algorithms on both synthetic data and real-world data. Numerical experiments show that LMB efficiently and effectively preserves the neighbourhood and uncovers the latent embedded structure of the manifold. LMB also has a low complexity of
for n data points."
2016,A Powerful Generative Model Using Random Weights for the Deep Image Representation.,"To what extent is the success of deep visualization due to the training? Could we do deep visualization using untrained, random weight networks? To address this issue, we explore new and powerful generative models for three popular deep visualization tasks using untrained, random weight convolutional neural networks. First we invert representations in feature spaces and reconstruct images from white noise inputs. The reconstruction quality is statistically higher than that of the same method applied on well trained networks with the same architecture. Next we synthesize textures using scaled correlations of representations in multiple layers and our results are almost indistinguishable with the original natural texture and the synthesized textures based on the trained network. Third, by recasting the content of an image in the style of various artworks, we create artistic images with high perceptual quality, highly competitive to the prior work of Gatys et al. on pretrained networks. To our knowledge this is the first demonstration of image representations using untrained deep neural networks. Our work provides a new and fascinating tool to study the representation of deep network architecture and sheds light on new understandings on deep visualization. It may possibly lead to a way to compare network architectures without training.
"
2016,In a World That Counts: Clustering and Detecting Fake Social Engagement at Scale.,"How can web services that depend on user generated content discern fake social engagement activities by spammers from legitimate ones? In this paper, we focus on the social site of YouTube and the problem of identifying bad actors posting inorganic contents and inflating the count of social engagement metrics. We propose an effective method, Leas (Local Expansion at Scale), and show how the fake engagement activities on YouTube can be tracked over time by analyzing the temporal graph based on the engagement behavior pattern between users and YouTube videos. With the domain knowledge of spammer seeds, we formulate and tackle the problem in a semi-supervised manner --- with the objective of searching for individuals that have similar pattern of behavior as the known seeds --- based on a graph diffusion process via local spectral subspace. We offer a fast, scalable MapReduce deployment adapted from the localized spectral clustering algorithm. We demonstrate the effectiveness of our deployment at Google by achieving a manual review accuracy of 98% on YouTube Comments graph in practice. Comparing with the state-of-the-art algorithm CopyCatch, Leas achieves 10 times faster running time on average. Leas is now actively in use at Google, searching for daily deceptive practices on YouTube's engagement graph spanning over a billion users."
2016,The Lifecycle and Cascade of WeChat Social Messaging Groups.,"Social instant messaging services are emerging as a transformative form with which people connect, communicate with friends in their daily life they catalyze the formation of social groups, and they bring people stronger sense of community and connection. However, research community still knows little about the formation and evolution of groups in the context of social messaging their lifecycles, the change in their underlying structures over time, and the diffusion processes by which they develop new members. In this paper, we analyze the daily usage logs from WeChat group messaging platform the largest standalone messaging communication service in China with the goal of understanding the processes by which social messaging groups come together, grow new members, and evolve over time. Specifically, we discover a strong dichotomy among groups in terms of their lifecycle, and develop a separability model by taking into account a broad range of group-level features, showing that long-term and short-term groups are inherently distinct. We also found that the lifecycle of messaging groups is largely dependent on their social roles and functions in users' daily social experiences and specific purposes. Given the strong separability between the long-term and short-term groups, we further address the problem concerning the early prediction of successful communities. In addition to modeling the growth and evolution from group-level perspective, we investigate the individual-level attributes of group members and study the diffusion process by which groups gain new members. By considering members' historical engagement behavior as well as the local social network structure that they embedded in, we develop a membership cascade model and demonstrate the effectiveness by achieving AUC of 95.31% in predicting inviter, and an AUC of 98.66% in predicting invitee."
2016,Convergent Learning: Do different neural networks learn the same representations?,"Recent success in training deep neural networks have prompted active investigation into the features learned on their intermediate layers. Such research is difficult because it requires making sense of non-linear computations performed by millions of parameters, but valuable because it increases our ability to understand current models and create improved versions of them. In this paper we investigate the extent to which neural networks exhibit what we call convergent learning, which is when the representations learned by multiple nets converge to a set of features which are either individually similar between networks or where subsets of features span similar low-dimensional spaces. We propose a specific method of probing representations: training multiple networks and then comparing and contrasting their individual, learned representations at the level of neurons or groups of neurons. We begin research into this question using three techniques to approximately align different neural networks on a feature level: a bipartite matching approach that makes one-to-one assignments between neurons, a sparse prediction approach that finds one-to-many mappings, and a spectral clustering approach that finds many-to-many mappings. This initial investigation reveals a few previously unknown properties of neural networks, and we argue that future research into the question of convergent learning will yield many more. The insights described here include (1) that some features are learned reliably in multiple networks, yet other features are not consistently learned; (2) that units learn to span low-dimensional subspaces and, while these subspaces are common to multiple networks, the specific basis vectors learned are not; (3) that the representation codes show evidence of being a mix between a local code and slightly, but not fully, distributed codes across multiple units."
2015,Use of Local Group Information to Identify Communities in Networks.,"The recent interest in networks has inspired a broad range of work on algorithms and techniques to characterize, identify, and extract communities from networks. Such efforts are complicated by a lack of consensus on what a ‚Äúcommunity‚Äù truly is, and these disagreements have led to a wide variety of mathematical formulations for describing communities. Often, these mathematical formulations, such as modularity and conductance, have been founded in the general principle that communities, like a G(n, p) graph, are ‚Äúround,‚Äù with connections throughout the entire community, and so algorithms were developed to optimize such mathematical measures. More recently, a variety of algorithms have been developed that, rather than expecting connectivity through the entire community, seek out very small groups of well-connected nodes and then connect these groups into larger communities. In this article, we examine seven real networks, each containing external annotation that allows us to identify ‚Äúannotated communities.‚Äù A study of these annotated communities gives insight into why the second category of community detection algorithms may be more successful than the first category. We then present a flexible algorithm template that is based on the idea of joining together small sets of nodes. In this template, we first identify very small, tightly connected ‚Äúsubcommunities‚Äù of nodes, each corresponding to a single node‚Äôs ‚Äúperception‚Äù of the network around it. We then create a new network in which each node represents such a subcommunity, and then identify communities in this new network. Because each node can appear in multiple subcommunities, this method allows us to detect overlapping communities. When evaluated on real data, we show that our template outperforms many other state-of-the-art algorithms."
2015,Detecting Overlapping Communities from Local Spectral Subspaces.,"Abstract:
Based on the definition of local spectral subspace, we propose a novel approach called LOSP for local overlapping community detection. Using the power method for a few steps, LOSP finds an approximate invariant subspace, which depicts the embedding of the local neighborhood structure around the seeds of interest. LOSP then identifies the local community expanded from the given seeds by seeking a sparse indicator vector in the subspace where the seeds are in its support. We provide a systematic investigation on LOSP, and thoroughly evaluate it on large real world networks across multiple domains. With the prior information of very few seed members, LOSP can detect the remaining members of a target community with high accuracy. Experiments demonstrate that LOSP outperforms the Heat Kernel and PageRank diffusions. Using LOSP as a subroutine, we further address the problem of multiple membership identification, which aims to find all the communities a single vertex belongs to. High F1 scores are achieved in detecting multiple local communities with respect to arbitrary single seed for various large real world networks."
2015,Convergent Learning: Do different neural networks learn the same representations?,"Recent successes in training large, deep neural networks (DNNs) have prompted active investigation into the underlying representations learned on their intermediate layers. Such research is difficult because it requires making sense of non-linear computations performed by millions of learned parameters. However, despite the difficulty, such research is valuable because it increases our ability to understand current models and training algorithms and thus create improved versions of them. We argue for the value of investigating whether neural networks exhibit what we call convergent learning, which is when separately trained DNNs learn features that converge to span similar spaces. We further begin research into this question by introducing two techniques to approximately align neurons from two networks: a bipartite matching approach that makes one-to-one assignments between neurons and a spectral clustering approach that finds many-to-many mappings. Our initial approach to answering this question reveals many interesting, previously unknown properties of neural networks, and we argue that future research into the question of convergent learning will yield many more. The insights described here include (1) that some features are learned reliably in multiple networks, yet other features are not consistently learned; and (2) that units learn to span low-dimensional subspaces and, while these subspaces are common to multiple networks, the specific basis vectors learned are not; (3) that the average activation values of neurons vary considerably within a network, yet the mean activation values across different networks converge to an almost identical distribution."
2015,Uncovering the Small Community Structure in Large Networks: A Local Spectral Approach.,"Large graphs arise in a number of contexts and understanding their structure and extracting information from them is an important research area. Early algorithms on mining communities have focused on the global structure, and often run in time functional to the size of the entire graph. Nowadays, as we often explore networks with billions of vertices and find communities of size hundreds, it is crucial to shift our attention from macroscopic structure to microscopic structure when dealing with large networks. A growing body of work has been adopting local expansion methods in order to identify the community from a few exemplary seed members. %Very few approaches can systematically demonstrate both high efficiency and effectiveness that significantly stands out amongst the divergent approaches in finding communities.
In this paper, we propose a novel approach for finding overlapping communities called LEMON (Local Expansion via Minimum One Norm). Different from PageRank-like diffusion methods, LEMON finds the community by seeking a sparse vector in the span of the local spectra such that the seeds are in its support. We show that LEMON can achieve the highest detection accuracy among state-of-the-art proposals. The running time depends on the size of the community rather than that of the entire graph. The algorithm is easy to implement, and is highly parallelizable.
Moreover, given that networks are not all similar in nature, a comprehensive analysis on how the local expansion approach is suited for uncovering communities in different networks is still lacking. We thoroughly evaluate our approach using both synthetic and real-world datasets across different domains, and analyze the empirical variations when applying our method to inherently different networks in practice. In addition, the heuristics on how the quality and quantity of the seed set would affect the performance are provided."
2014,A separability framework for analyzing community structure.,"Four major factors govern the intricacies of community extraction in networks: (1) the literature offers a multitude of disparate community detection algorithms whose output exhibits high structural variability across the collection, (2) communities identified by algorithms may differ structurally from real communities that arise in practice, (3) there is no consensus characterizing how to discriminate communities from noncommunities, and (4) the application domain includes a wide variety of networks of fundamentally different natures. In this article, we present a class separability framework to tackle these challenges through a comprehensive analysis of community properties. Our approach enables the assessment of the structural dissimilarity among the output of multiple community detection algorithms and between the output of algorithms and communities that arise in practice. In addition, our method provides us with a way to organize the vast collection of community detection algorithms by grouping those that behave similarly. Finally, we identify the most discriminative graph-theoretical properties of community signature and the small subset of properties that account for most of the biases of the different community detection algorithms. We illustrate our approach with an experimental analysis, which reveals nuances of the structure of real and extracted communities. In our experiments, we furnish our framework with the output of 10 different community detection procedures, representative of categories of popular algorithms available in the literature, applied to a diverse collection of large-scale real network datasets whose domains span biology, online shopping, and social systems. We also analyze communities identified by annotations that accompany the data, which reflect exemplar communities in various domain. We characterize these communities using a broad spectrum of community properties to produce the different structural classes. As our experiments show that community structure is not a universal concept, our framework enables an informed choice of the most suitable community detection method for identifying communities of a specific type in a given network and allows for a comparison of existing community detection algorithms while guiding the design of new ones."
2013,"Extracting the Core Structure of Social Networks Using (?, ?)-Communities.","An (?, ?)-community is a connected subgraph C with each vertex in C connected to at least ? vertices of C (self-loops counted) and each vertex outside of C connected to at most ? vertices of C (? < ?). In this paper, we present a heuristic algorithm that in practice successfully finds a fundamental community structure. We also explore the structure of (?, ?)-communities in various social networks. (?, ?)-communities are well clustered into a small number of disjoint groups, and there are no isolated (?, ?)-communities scattered between these groups. Two (?, ?)-communities in the same group have significant overlap, while those in different groups have extremely small resemblance. A surprising core structure is discovered by taking the intersection of each group of massively overlapping (?, ?)-communities. Further, similar experiments on random graphs demonstrate that the core structure found in many social networks is due to their underlying social structure, rather than to high-degree vertices or a particular degree distribution."
2013,Learning to predict reciprocity and triadic closure in social networks.,"We study how links are formed in social networks. In particular, we focus on investigating how a reciprocal (two-way) link, the basic relationship in social networks, is developed from a parasocial (one-way) relationship and how the relationships further develop into triadic closure, one of the fundamental processes of link formation.
We first investigate how geographic distance and interactions between users influence the formation of link structure among users. Then we study how social theories including homophily, social balance, and social status are satisfied over networks with parasocial and reciprocal relationships. The study unveils several interesting phenomena. For example, ‚Äúfriend's friend is a friend‚Äù indeed exists in the reciprocal relationship network, but does not hold in the parasocial relationship network.
We propose a learning framework to formulate the problems of predicting reciprocity and triadic closure into a graphical model. We demonstrate that it is possible to accurately infer 90% of reciprocal relationships in a Twitter network. The proposed model also achieves better performance (+20--30% in terms of F1-measure) than several alternative methods for predicting the triadic closure formation."
2013,Sign Cauchy Projections and Chi-Square Kernel.,"The method of stable random projections is popular for efficiently computing the Lp distances in high dimension (where 0<p<=2), using small space. Because it adopts nonadaptive linear projections, this method is naturally suitable when the data are collected in a dynamic streaming fashion (i.e., turnstile data streams). In this paper, we propose to use only the signs of the projected data and analyze the probability of collision (i.e., when the two signs differ). We derive a bound of the collision probability which is exact when p=2 and becomes less sharp when p moves away from 2. Interestingly, when p=1 (i.e., Cauchy random projections), we show that the probability of collision can be accurately approximated as functions of the chi-square similarity. For example, when the (un-normalized) data are binary, the maximum approximation error of the collision probability is smaller than 0.0192. In text and vision applications, the chi-square similarity is a popular measure for nonnegative data when the features are generated from histograms. Our experiments confirm that the proposed method is promising for large-scale learning applications."
2012,"Information, Data, Security in a Networked Future.","The digital information revolution begins as giants such as Alan Turing, Claude Shannon and John von neumann, among many others, recognize the power of digital representations and programmable computers. Although rooted in the technology of his time, Vannevar Bush's portrait of the information revolution has emerged and fl ourished especially in the form of the World Wide Web resting atop the global Internet.
The panelists will explore some specifi cs of the digital information revolution, notably theory and practice in securing, authenticating and maintaining the integrity of information (Cerf); and roots of modern cryptography and current topics in this area (rivest and Shamir). They will also gain insight into the long-term problem of identifying, fi nding, and assuring the integrity of digital objects in the most general sense of that term (Kahn). Finally, they look at how our understanding of computer science is changing (Hopcroft) and how that evolution will affect the digital world in which are we spending an increasing fraction of our daily lives."
2012,Use of Supervised Learning to Predict Directionality of Links in a Network.,"Abstract
Often, the information contained in network data is incomplete. Many avenues of research are aimed at addressing this incompleteness. For example, the link prediction problem attempts to identify which missing links are most likely to exist in the complete network. In this paper, we consider a related, but different, problem: predicting the directions of links in a directed network. We treat this problem as a supervised learning problem in which the directions of some edges are known. We calculate various features of each known edge based on its position in the network, and use a Support Vector Machine to predict the unknown directions of edges. We consider four networks, and show that in each case, this method performs significantly better than other compared methods."
2012,Making the World a Better Place.,"Abstract
The papers in this book detail Dexters research contributions, which are profound. I would like to highlight another contribution Dexter has made that affects us all in the department every day"
2012,Future Directions in Computer Science Research.,"Abstract
Over the last 40 years the computer science research was focused on making computers useful. Areas included programming languages, compilers, operating systems, data structures and algorithms. These are still important topics but with the merging of computing and communication, the emergence of social networks, and the large amount of information in digital form, focus is shifting to applications such as the structure of networks and extracting information from large data sets. This talk will give a brief vision of the future and then an introduction to the science base that needs to be formed to support these new directions."
2012,On the separability of structural classes of communities.,"Three major factors govern the intricacies of community extraction in networks: (1) the application domain includes a wide variety of networks of fundamentally different natures, (2) the literature offers a multitude of disparate community detection algorithms, and (3) there is no consensus characterizing how to discriminate communities from non-communities. In this paper, we present a comprehensive analysis of community properties through a class separability framework. Our approach enables the assessement of the structural dissimilarity among the output of multiple community detection algorithms and between the output of algorithms and communities that arise in practice. To demostrate this concept, we furnish our method with a large set of structural properties and multiple community detection algorithms. Applied to a diverse collection of large scale network datasets, the analysis reveals that (1) the different detection algorithms extract fundamentally different structures; (2) the structure of communities that arise in practice is closest to that of communities that random-walk-based algorithms extract, although still siginificantly different from that of the output of all the algorithms; and (3) a small subset of the properties are nearly as discriminative as the full set, while making explicit the ways in which the algorithms produce biases. Our framework enables an informed choice of the most suitable community detection method for a given purpose and network and allows for a comparison of existing community detection algorithms while guiding the design of new ones."
2012,Feature-Enhanced Probabilistic Models for Diffusion Network Inference.,"Abstract
Cascading processes, such as disease contagion, viral marketing, and information diffusion, are a pervasive phenomenon in many types of networks. The problem of devising intervention strategies to facilitate or inhibit such processes has recently received considerable attention. However, a major challenge is that the underlying network is often unknown. In this paper, we revisit the problem of inferring latent network structure given observations from a diffusion process, such as the spread of trending topics in social media. We define a family of novel probabilistic models that can explain recurrent cascading behavior, and take into account not only the time differences between events but also a richer set of additional features. We show that MAP inference is tractable and can therefore scale to very large real-world networks. Further, we demonstrate the effectiveness of our approach by inferring the underlying network structure of a subset of the popular Twitter following network by analyzing the topics of a large number of messages posted by users over a 10-month period. Experimental results show that our models accurately recover the links of the Twitter network, and significantly improve the performance over previous models based entirely on time."
2012,On the Impact of Turing Machines.,"Abstract
Turing contributed a simple model of computation that has become the definition of computable. A function is considered to be computable if and only if it is computable on Turing‚Äôs model of computation. Since our notion of computable is informal and Turing‚Äôs model gives a precise definition of computable, we cannot prove the two equivalent. However, for every mathematical definition of computable that has been proposed, a proof has been developed that any function computable by the proposed model is also computable by Turing‚Äôs model.
Turing‚Äôs model is very simple, it consists of an infinite tape made up of cells, each cell capable of holding one of a finite set of symbols, along with a control with a finite number of states and a tape head by which the finite control can scan the tape and read the content of the cell scanned. A move consists of reading the contents of the scanned cell and depending on the internal state of the finite state control, writing a new symbol in the cell, moving the read head one cell right or one cell left, and changing the internal state of the finite control to a new state.
Although logicians had their own models of computable, Turing‚Äôs model made the notion of computable accessible to a larger community. The impact of a mathematical model that corresponded to a physical device and allowed one to picture and more fully understand the notion of computability accelerated the science of computability in a way which many do not appreciate and is the function of this talk.
One of the major advances came when Hartmanis and Stearns used the Turing model to define complexity classes. This then gave a formal definition to the intuitive notion of polynomial time algorithms. It helped led to asymptotic complexity as a way to compare performance of algorithms.
Another major advance was that the Turing model lead to the notion of an instantaneous description of a computation and a valid computation. An instantaneous description is a string that completely describes a computation at one instance of time. A valid computation is a sequence of successive instantaneous description.
Once a valid computation was represented by a string of symbols it was quickly recognized that a valid computation of a Turing machine could be expressed as the intersection of two context-free languages and hence the question whether the intersection was empty was undecidable. Many other problems arising in computer science were quickly shown to be undecidable. In the mid sixties the language ALGOL was invented and was described by a context-free grammar. However, as people soon noticed that what a program did sometimes depended on the compiler used. It was quickly discovered that the context-free grammar describing ALGOL was ambiguous. When researcher set out to write an algorithm to determine if a context-free grammar was ambiguous they quickly discovered that this problem was also undecidable.
One of the major discoveries of this century was when Stephan Cook proved that every problem in polynomial time could be reduced to the problem of satisfying a formula in conjunctive normal form. This lead to the notion of NP-complete problems and that many problems such as integer programming, finding the maximal clique, and many others were really all equivalent.
Although Turing‚Äôs model was very simple it was that simplicity that lead to major advances in computer science."
2012,Using community information to improve the precision of link prediction methods.,"Because network data is often incomplete, researchers consider the link prediction problem, which asks which non-existent edges in an incomplete network are most likely to exist in the complete network. Classical approaches compute the 'similarity' of two nodes, and conclude that highly similar nodes are most likely to be connected in the complete network. Here, we consider several such similarity-based measures, but supplement the similarity calculations with community information. We show that for many networks, the inclusion of community information improves the accuracy of similarity-based link prediction methods."
2011,The Future of Computer Science.,"Computer science is undergoing a fundamental change and is reshaping our understanding of the world. An important aspect of this change is the theory and applications dealing with the gathering and analyzing of large real-world datasets. In this paper, we introduce four research projects in which processing and interpreting large data sets is a central focus. Innovative ways of analyzing such data sets allow us to extract useful information that we would never have obtained from small or synthetic data sets, thus providing us with new insights into the real world."
2011,Who will follow you back?: reciprocal relationship prediction.,"We study the extent to which the formation of a two-way relationship can be predicted in a dynamic social network. A two-way (called reciprocal) relationship, usually developed from a one-way (parasocial) relationship, represents a more trustful relationship between people. Understanding the formation of two-way relationships can provide us insights into the micro-level dynamics of the social network, such as what is the underlying community structure and how users influence each other. Employing Twitter as a source for our experimental data, we propose a learning framework to formulate the problem of reciprocal relationship prediction into a graphical model. The framework incorporates social theories into a machine learning model. We demonstrate that it is possible to accurately infer 90% of reciprocal relationships in a dynamic network. Our study provides strong evidence of the existence of the structural balance among reciprocal relationships. In addition, we have some interesting findings, e.g., the likelihood of two ""elite"" users creating a reciprocal relationships is nearly 8 times higher than the likelihood of two ordinary users. More importantly, our findings have potential implications such as how social structures can be inferred from individuals' behaviors."
2011,Detecting Community Kernels in Large Social Networks.,"Abstract:
In many social networks, there exist two types of users that exhibit different influence and different behavior. For instance, statistics have shown that less than 1% of the Twitter users (e.g. entertainers, politicians, writers) produce 50% of its content, while the others (e.g. fans, followers, readers) have much less influence and completely different social behavior. In this paper, we define and explore a novel problem called community kernel detection in order to uncover the hidden community structure in large social networks. We discover that influential users pay closer attention to those who are more similar to them, which leads to a natural partition into different community kernels. We propose Greedy and We BA, two efficient algorithms for finding community kernels in large social networks. Greedy is based on maximum cardinality search, while We BA formalizes the problem in an optimization framework. We conduct experiments on three large social networks: Twitter, Wikipedia, and Coauthor, which show that We BA achieves an average 15%-50% performance improvement over the other state-of-the-art algorithms, and We BA is on average 6-2,000 times faster in detecting community kernels."
2011,"Detecting the Structure of Social Networks Using (Œ±, Œ≤)-Communities.","Abstract
An (Œ±,Œ≤)-community is a subset of vertices C with each vertex in C connected to at least Œ≤ vertices of C (self-loops counted) and each vertex outside of C connected to at most Œ± vertices of C (Œ±‚Äâ<‚ÄâŒ≤) [9]. In this paper, we present a heuristic (Œ±,Œ≤)-Community algorithm, which in practice successfully finds (Œ±,Œ≤)-communities of a given size. The structure of (Œ±,Œ≤)-communities in several large-scale social graphs is explored, and a surprising core structure is discovered by taking the intersection of a group of massively overlapping (Œ±,Œ≤)-communities. For large community size k, the (Œ±,Œ≤)-communities are well clustered into a small number of disjoint cores, and there are no isolated (Œ±,Œ≤)-communities scattered between these densely-clustered cores. The (Œ±,Œ≤)-communities from the same group have significant overlap among them, and those from distinct groups have extremely small pairwise resemblance. The number of cores decreases as k increases, and there are no bridges of intermediate (Œ±,Œ≤)-communities connecting one core to another. The cores obtained for a smaller k either disappear or merge into the cores obtained for a larger k. Further, similar experiments on random graph models demonstrate that the core structure displayed in various social graphs is due to the underlying social structure of these real-world networks, rather than due to high-degree vertices or a particular degree distribution."
2011,The web of topics: discovering the topology of topic evolution in a corpus.,"In this paper we study how to discover the evolution of topics over time in a time-stamped document collection. Our approach is uniquely designed to capture the rich topology of topic evolution inherent in the corpus. Instead of characterizing the evolving topics at fixed time points, we conceptually define a topic as a quantized unit of evolutionary change in content and discover topics with the time of their appearance in the corpus. Discovered topics are then connected to form a topic evolution graph using a measure derived from the underlying document network. Our approach allows inhomogeneous distribution of topics over time and does not impose any topological restriction in topic evolution graphs. We evaluate our algorithm on the ACM corpus.
The topic evolution graphs obtained from the ACM corpus provide an effective and concrete summary of the corpus with remarkably rich topology that are congruent to our background knowledge. In a finer resolution, the graphs reveal concrete information about the corpus that were previously unknown to us, suggesting the utility of our approach as a navigational tool for the corpus."
2010,New Research Directions in the Information Age.,"Abstract
Computer Science has expanded in may new directions giving rise to a large number of interesting and important research problems. This talk will explore a number of new areas and open problems in these areas that need attention. Areas include tracking the flow of ideas in scientific literature, identifying key papers and how a discipline evolved, extracting information from unstructured data sources, the definition of communities in different types of graphs and the structure and evolution of social networks."
2010,Recovering Social Networks from Contagion Information.,"Abstract
Many algorithms for analyzing social networks assume that the structure of the network is known, but this is not always a reasonable assumption. We wish to reconstruct an underlying network given data about how some property, such as disease, has spread through the network. Properties may spread through a network in different ways: for instance, an individual may learn information as soon as one of his neighbors has learned that information, but political beliefs may follow a different type of model. We create algorithms for discovering underlying networks that would give rise to the diffusion in these models."
2010,Community Structure in Large Complex Networks.,"Abstract
In this paper, we establish the definition of community fundamentally different from what was commonly accepted in previous studies, where communities were typically assumed to be densely connected internally but sparsely connected to the rest of the network. A community should be considered as a densely connected subset in which the probability of an edge between two randomly-picked vertices is higher than average. Moreover, a community should also be well connected to the remaining network, that is, the number of edges connecting a community to the rest of the graph should be significant. In order to identify a well-defined community, we provide rigorous definitions of two relevant terms: ‚Äúwhiskers‚Äù and the ‚Äúcore‚Äù. Whiskers correspond to subsets of vertices that are barely connected to the rest of the network, while the core exclusively contains the type of community we are interested in. We have proven that detecting whiskers, or equivalently, extracting the core, is an NP-complete problem for weighted graphs. Then, three heuristic algorithms are proposed for finding an approximate core and are evaluated for their performance on large networks, which reveals the common existence of the core structure in both random and real-world graphs. Further, well-defined communities can be extracted from the core using a number of techniques, and the experimental results not only justify our intuitive notion of community, but also demonstrate the existence of large-scale communities in various complex networks."
2008,Local Computation of PageRank Contributions.,"Motivated by the problem of detecting link-spam, we consider the following graph-theoretic primitive: Given a webgraph G, a vertex v in G, and a parameter delta in (0, 1), compute the set of all vertices that contribute to v at least a delta-fraction of v's PageRank. We call this set the delta-contributing set of v. To this end, we define the contribution vector of v to be the vector whose entries measure the contributions of every vertex to the PageRank of v. A local algorithm is one that produces a solution by adaptively examining only a small portion of the input graph near a specified vertex. We give an efficient local algorithm that computes an epsilon-approximation of the contribution vector for a given vertex by adaptively examining O(1/epsilon) vertices. Using this algorithm, we give a local approximation algorithm for the primitive defined above. Specifically, we give an algorithm that returns a set containing the delta-contributing set of v and at most O(1/delta) vertices from the delta/2 contributing set of v, and that does so by examining at most O(1/delta) vertices. We also give a local algorithm for solving the following problem: if there exist k vertices that contribute a p-fraction to the PageRank of v, find a set of k vertices that contribute at least a (p - epsilon) fraction to the PageRank of v. In this case, we prove that our algorithm examines at most O(k/epsilon) vertices."
2008,Manipulation-Resistant Reputations Using Hitting Time.,"Popular reputation systems for linked networks can be manipulated by spammers who strategically place links. In PageRank, pages endorse others by placing links, and the global link structure is analyzed to determine the reputation of each page. Though this is meant to be a global measure, page v can boost its own PageRank considerably using a simple self-endorsement strategy: placing outlinks to form short directed cycles. In contrast, we show that expected hitting time - the time to reach v in a random walk - measures essentially the same quantity as PageRank, but does not depend on v's outlinks. We develop a reputation system based on hitting time and show that it resists tampering by individuals or groups who strategically place outlinks. We also present an algorithm to efficiently compute hitting time for all nodes in a massive graph; conventional algorithms do not scale adequately."
2008,Robust PageRank and locally computable spam detection features.,"Since the link structure of the web is an important element in ranking systems on search engines, web spammers widely use the link structure of the web to increase the rank of their pages. Various link-based features of web pages have been introduced and have proven effective at identifying link spam. One particularly successful family of features (as described in the SpamRank algorithm), is based on examining the sets of pages that contribute most to the PageRank of a given vertex, called supporting sets. In a recent paper, the current authors described an algorithm for efficiently computing, for a single specified vertex, an approximation of its supporting sets. In this paper, we describe several link-based spam-detection features, both supervised and unsupervised, that can be derived from these approximate supporting sets. In particular, we examine the size of a node's supporting sets and the approximate l2 norm of the PageRank contributions from other nodes. As a supervised feature, we examine the composition of a node's supporting sets. We perform experiments on two labeled real data sets to demonstrate the effectiveness of these features for spam detection, and demonstrate that these features can be computed efficiently. Furthermore, we design a variation of PageRank (called Robust PageRank) that incorporates some of these features into its ranking, argue that this variation is more robust against link spam engineering, and give an algorithm for approximating Robust PageRank."
2008,Computer Science in the Information Age.,"Abstract
The last forty years have seen computer science evolve as a major academic discipline. Today the field is undergoing a major change. Some of the drivers of this change are the internet, the world wide web, large sensor networks, large quantities of information in digital form and the wide spread use of computers for accessing information. This change is requiring universities to revise the content of computer science programs. This talk will cover the changes in the theoretical foundations needed to support information access in the coming years."
2008,On the Stability of Web Crawling and Web Search.,"Abstract
In this paper, we analyze a graph-theoretic property motivated by web crawling. We introduce a notion of stable cores, which is the set of web pages that are usually contained in the crawling buffer when the buffer size is smaller than the total number of web pages. We analyze the size of core in a random graph model based on the bounded Pareto power law distribution. We prove that a core of significant size exists for a large range of parameters 2‚Äâ<‚ÄâŒ±<‚Äâ3 for the power law."
2007,Finding (Short) Paths in Social Networks.,"While several analytic models aim to explain the existence of short paths in social networks such as the web, relatively few address the problem of efficiently finding them, especially in a decentralized manner. Since developing purely decentralized search algorithms in general social-network models appears hard, we relax the notion of decentralized search by allowing the option of storing a small amount of preprocessed information about the network. We show that one can identify a small set of vertices in an undirected social network so that connectivity information of the vertices in this set can be used in conjunction with the local connectivity properties to perform decentralized search and find short paths between vertices. Our results are for random graphs with power law degree distribution generated by a variant of the expected degree model."
2007,Spectral clustering with limited independence.,"This paper considers the well-studied problem of clustering a set of objects under a probabilistic model of data in which each object is represented as a vector over the set of features, and there are only k different types of objects. In general, earlier results (mixture models and ""planted"" problems on graphs) often assumed that all coordinates of all objects are independent random variables. They then appeal to the theory of random matrices in order to infer spectral properties of the feature x object matrix. However, in most practical applications, assuming full independence is not realistic.
Instead, we only assume that the objects are independent, but the coordinates of each object may not be. We first generalize the required results for random matrices to this case of limited independence using some new techniques developed in Functional Analysis. Surprisingly, we are able to prove results that are quite similar to the fully independent case modulo an extra logarithmic factor. Using these bounds, we develop clustering algorithms for the more general mixture models. Our clustering algorithms have a substantially different and perhaps simpler ""clean-up"" phase than known algorithms. We show that our model subsumes not only the planted partition random graph models, but also another set of models under which there is a body of clustering algorithms, namely the Gaussian and log-concave mixture models."
2007,Manipulation-Resistant Reputations Using Hitting Time.,"Abstract
Popular reputation systems for linked networks can be manipulated by spammers who strategically place links. The reputation of node v is interpreted as the world‚Äôs opinion of v‚Äôs importance. In PageRank [4], v‚Äôs own opinion can be seen to have considerable influence on her reputation, where v expresses a high opinion of herself by participating in short directed cycles. In contrast, we show that expected hitting time ‚Äî the time to reach v in a random walk ‚Äî measures essentially the same quantity as PageRank, but excludes v‚Äôs opinion. We make these notions precise, and show that a reputation system based on hitting time resists tampering by individuals or groups who strategically place outlinks. We also present an algorithm to efficiently compute hitting time for all nodes in a massive graph; conventional algorithms do not scale adequately."
2007,Local Computation of PageRank Contributions.,"Abstract
Motivated by the problem of detecting link-spam, we consider the following graph-theoretic primitive: Given a webgraph G, a vertex v in G, and a parameter Œ¥‚Äâ‚àà‚Äâ(0,1), compute the set of all vertices that contribute to v at least a Œ¥ fraction of v‚Äôs PageRank. We call this set the Œ¥-contributing set of v. To this end, we define the contribution vector of v to be the vector whose entries measure the contributions of every vertex to the PageRank of v. A local algorithm is one that produces a solution by adaptively examining only a small portion of the input graph near a specified vertex. We give an efficient local algorithm that computes an Œµ-approximation of the contribution vector for a given vertex by adaptively examining O(1/Œµ) vertices. Using this algorithm, we give a local approximation algorithm for the primitive defined above. Specifically, we give an algorithm that returns a set containing the Œ¥-contributing set of v and at most O(1/Œ¥) vertices from the Œ¥/2-contributing set of v, and which does so by examining at most O(1/Œ¥) vertices. We also give a local algorithm for solving the following problem: If there exist k vertices that contribute a œÅ-fraction to the PageRank of v, find a set of k vertices that contribute at least a (œÅ‚Äâ‚àí‚ÄâŒµ)-fraction to the PageRank of v. In this case, we prove that our algorithm examines at most O(k/Œµ) vertices."
2006,Spectral Clustering by Recursive Partitioning.,"Abstract
In this paper, we analyze the second eigenvector technique of spectral partitioning on the planted partition random graph model, by constructing a recursive algorithm using the second eigenvectors in order to learn the planted partitions. The correctness of our algorithm is not based on the ratio-cut interpretation of the second eigenvector, but exploits instead the stability of the eigenvector subspace. As a result, we get an improved cluster separation bound in terms of dependence on the maximum variance. We also extend our results for a clustering problem in the case of sparse graphs."
2005,On Learning Mixtures of Heavy-Tailed Distributions.,"Abstract:
We consider the problem of learning mixtures of arbitrary symmetric distributions. We formulate sufficient separation conditions and present a learning algorithm with provable guarantees for mixtures of distributions that satisfy these separation conditions. Our bounds are independent of the variances of the distributions; to the best of our knowledge, there were no previous algorithms known with provable learning guarantees for distributions having infinite variance and/or expectation. For Gaussians and log-concave distributions, our results match the best known sufficient separation conditions by D. Achlioptas and F. McSherry (2005) and S. Vempala and G. Wang (2004). Our algorithm requires a sample of size O/spl tilde/(dk), where d is the number of dimensions and k is the number of distributions in the mixture. We also show that for isotropic power-laws, exponential, and Gaussian distributions, our separation condition is optimal up to a constant factor."
2005,Error bounds for correlation clustering.,"This paper presents a learning theoretical analysis of correlation clustering (Bansal et al., 2002). In particular, we give bounds on the error with which correlation clustering recovers the correct partition in a planted partition model (Condon & Karp, 2001; McSherry, 2001). Using these bounds, we analyze how the accuracy of correlation clustering scales with the number of clusters and the sparsity of the graph. We also propose a statistical test that analyzes the significance of the clustering found by correlation clustering."
2005,Correctness of a gossip based membership protocol.,"The importance of scalability and fault-tolerance in modern distributed systems has led to considerable research in multicast protocols using gossip. In a gossip protocol, each node forwards messages to a small set of ìgossip partnersî chosen at random from the entire group membership. By discarding the strong reliability guarantees of traditional protocols in favour of probabilistic guarantees, gossip protocols can deliver greater scalability and fault tolerance. In early gossip algorithms, partners were chosen uniformly at random from the entire membership, limiting scalability because of the resources required to store and maintain complete membership views at each node. Later protocols avoided this issue by storing much smaller random subsets of the membership at each node, and choosing gossip partners only from these local views. Such protocols are subtle: at least some local views must change in response to group membership changes in order to preserve connectivity and performance guarantees. While these protocols have been the subject of much simulation and analysis, formal proofs of key properties ñ in particular the probability of partitioning ñ have remained elusive. In this paper we give a new scalable gossip-based algorithm for local view maintenance, together with a proof that the expected time until a network partition is at least exponential in the square of the view size. We also develop probabilistic bounds on the in-degree (hence the load) of individual nodes, and argue that protocols lacking our reinforcement component eventually converge to star-like networks, whose connectivity depends on a small set of overloaded nodes. We also argue that the undirected connectivity graph is an expander, for which application-level gossip multi-cast protocols will converge rapidly. Our theoretical results are supported by simulations."
2004,Spectral Analysis of Random Graphs with Skewed Degree Distributions.,"Abstract:
We extend spectral methods to random graphs with skewed degree distributions through a degree based normalization closely connected to the normalized Laplacian. The normalization is based on intuition drawn from perturbation theory of random matrices, and has the effect of boosting the expectation of the random adjacency matrix without increasing the variances of its entries, leading to better perturbation bounds. The primary implication of this result lies in the realm of spectral analysis of random graphs with skewed degree distributions, such as the ubiquitous ""power law graphs"". Mihail and Papadimitriou (2002) argued that for randomly generated graphs satisfying a power law degree distribution, spectral analysis of the adjacency matrix simply produces the neighborhoods of the high degree nodes as its eigenvectors, and thus miss any embedded structure. We present a generalization of their model, incorporating latent structure, and prove that after applying our transformation, spectral analysis succeeds in recovering the latent structure with high probability."
2003,Natural communities in large linked networks.,"We are interested in finding natural communities in large-scale linked networks. Our ultimate goal is to track changes over time in such communities. For such temporal tracking, we require a clustering algorithm that is relatively stable under small perturbations of the input data. We have developed an efficient, scalable agglomerative strategy and applied it to the citation graph of the NEC CiteSeer database (250,000 papers; 4.5 million citations). Agglomerative clustering techniques are known to be unstable on data in which the community structure is not strong. We find that some communities are essentially random and thus unstable while others are natural and will appear in most clusterings. These natural communities will enable us to track the evolution of communities over time."
1992,A Paradigm for Robust Geometric Algorithms.,"Abstract
This paper explores a paradigm for producing geometrical algorithms in which logical decisions that depend on finite-precision numerical calculation cannot lead to failure. It applies this paradigm to the task of intersecting two convex polyhedral objects. A key tool in this work is a method of perturbing embedding polyhedra in ways consistent with their topology."
1991,A Case Study of Flexible Object Manipulation.,"This article describes a project undertaken to explore programming physical operations on complex flexible objects. Uncertainty about the exact state of the object makes it im possible to precisely specify the actions to be performed at the time the program is written. Furthermore, the detailed conse quences of manipulations on flexible objects cannot be deter mined before the action is performed. Lacking precise specifi cations, the programmer must abstract the essential properties of objects and actions. In an effort to study manipulation offlexible objects, a system to tie knots in rope with a robot arm was developed. The system includes an extensible graph representation for knots, a vision system that binds the contour of a physical rope to an abstract description, and a knot-tying language based on parametric motion commands. Knots of modest complexity, such as a bowline or figure 8, can be tied in a va riety of ropes with minimal constraints on the initial configu ration of the rope. The work highlights the importance of software engineering principles and a good programming en vironment for robot program development.

"
1989,Robust set operations on polyhedral solids.,"Abstract:
An algorithm for performing regularized Boolean operation on polyhedral solids is described. Robustness is achieved by adding symbolic reasoning as a supplemental step to resolve possible numerical uncertainty. Additionally, numerical redundancy and numerical computation based on derived quantities are reduced as much as possible. Experience with an implementation of the algorithm, using a unit-cube example as a simple test object for robustness, is discussed.< >"
1989,Electronic Prototyping.,"Abstract:
Electronic prototyping, i.e. building a computer model of an object to verify its design, faces a number of obstacles. The Cornell modeling and simulation project, which was created to develop the necessary science base to overcome these barriers, is discussed. In particular, the project's progress in improving robustness of solid modelers and its ongoing research in electronic prototyping are examined. A key component of the project, a model-driven simulator capable of supporting a wide range of multidisciplinary research, is described.< >"
1988,The Geometry of Projective Blending Surfaces.,"Blending surfaces smoothly join two or more primary surfaces that otherwise would intersect in edges. We outline the potential method for deriving blending surfaces, and explain why the method needs to be considered in projective parameter space, concentrating on the case of blending quadrics. Let W be the quadratic polynomial substituted for the homogenizing variable of parameter space. We show that a blending surface derived in projective parameter space is the projective image of a different blending surface derived in affine parameter space, provided that W = U2 for some linear U. All blending surfaces may therefore by classified on basis of the projective classification of W.
"
1988,Tracing surface intersections.,"We consider the problem of tracing the intersection of surfaces given either implicitly or parametrically. We give a numerical tracing procedure in which a third-order Taylor approximant is constructed for taking steps of variable length, and the points so found are improved by Newton iteration. We show how this construction relates to local parametrizations of the curve at singularities, and discuss our experience with the method. For plane curves, given implicitly, we show how desingularization techniques can be incorporated to trace correctly through all types of singularities. An implementation of this method is also discussed.
"
1988,Towards Implementing Robust Geometric Computations.,"Computational geometry has the unique opportunity to bridge the sharp gap between theoretical and applied computer science. Indeed, practical computations with geometric objects are of intense interest to a wide range of applied work including computer aided design, robotics, mathematics, engineering, etc. At the same time, these computations pose many challenging problems of considerable theoretical depth and interest. "
1987,Computer Science: The Emergence of a Discipline.,The continued rapid development of computer science will require an expansion of the science base and an influx of talented new researchers. Computers have already altered the way we think and live; now they will begin to elevate our knowledge of the world.
1987,Simulation of physical systems from geometric models.,"Abstract:
The design of an extensible system is discussed in which the behavior of physical objects is simulated from their models. Complex objects can be defined in a multiplicity of domains, including their geometric shape, their dynamic response to applied forces, and their controlled behavior. In response to unforeseen changes, e.g., for unexpected collisions, the object models are modified automatically during the simulation."
1986,The Impact of Robotics on Computer Science.,The rapid development of robotics and the resulting need for computer scientists to be better trained in traditional mathematics necessitate changes in computer science curricula.
1986,Reducing Multiple Object Motion Planning to Graph Searching.,"The motion planning problem for multiple objects is studied where an object is a 2-dimensional region whose sides are line segments parallel to the axes of ${\bf R}^2 $ and translations are the only motions allowed. Towards this end we analyze the structure of configuration space, the space of points that correspond to positions of the objects. In particular, we consider CONNECTED, the set of all points in configuration space that correspond to configurations of the objects where the objects form one connected component. We show that CONNECTED consists of faces of various dimensions such that if there is a path in CONNECTED between two 0-dimensional faces (vertices) of CONNECTED then there is a path between them along 1-dimensional faces (edges) of CONNECTED. It is known that if there is a motion between two configurations of CONNECTED then there is a path in CONNECTED between the configurations. Thus the existence of a motion between two vertices of CONNECTED implies a motion corresponding to a path along edges of CONNECTED. Hence the motion planning problem is reduced from a search of a high dimensional space to a graph searching problem.
From this result it is shown that motion planning for rectangles in a rectangular boundary is in PSPACE. Since it is known that the problem is PSPACE-hard, we conclude it is a PSPACE-complete problem.
"
1986,The Promise of Electronic Prototyping.,n/a
1985,"Routing, Merging, and Sorting on Parallel Models of Computation.","A variety of models have been proposed for the study of synchronous parallel computation. These models are reviewed and some prototype problems are studied further. Two classes of models are recognized, fixed connection networks and models based on a shared memory. Routing and sorting are prototype problems for the networks; in particular, they provide the basis for simulating the more powerful shared memory models. It is shown that a simple but important class of deterministic strategies (oblivious routing) is necessarily inefficient with respect to worst case analysis. Routing can be viewed as a special case of sorting, and the existence of an O(log n) sorting algorithm for some n processor fixed connection network has only recently been established by Ajtai, Komlos, and Szemeredi (ì15th ACM Sympos. on Theory of Comput.,î Boston, Mass., 1983, pp. 1ñ9). If the more powerful class of shared memory models is considered then it is possible to simply achieve an O(log n loglog n) sort via Valiant's parallel merging algorithm, which it is shown can be implemented on certain models. Within a spectrum of shared memory models, it is shown that loglog n is asymptotically optimal for n processors to merge two sorted lists containing n elements.
"
1985,Decreasing the Nesting Depth of Expressions Involving Square Roots.,"We develop the theory for decreasing the depth of nesting in expressions that contain square roots. We show exactly when fourth roots enable denesting of expressions not denestable with square roots only, When we restrict our attention to denesting over the real numbers, we show in fact that no roots other than square roots or fourth roots are ever useful for denesting expressions containing square roots only, thus characterising the denestable expressions in this case. We then proceed to describe new algorithms that accomplish such denesting.

"
1985,On the Movement of Robot Arms in 2-Dimensional Bounded Regions.,"The moverís problem is the following: can an object in 3-dimensional space be moved from one given position to another while avoiding obstacles? It is known that the general version of this problem involving objects with movable joints is PSPACE hard, even for a simple tree-like structure moving in a 3-dimensional region. In this paper, we investigate a 2-dimensional moverís problem in which the object is a robot arm with an arbitrary number of joints. In particular, we give a polynomial time algorithm for moving an arm confined within a circle from one given configuration to another. We also give a polynomial time algorithm for moving the arm from its initial position to a position in which the end of the arm reaches a given point within the circle. Finally, we show that 148 circles suffice to cover the boundary of the reachable region of a joint in an arm enclosed in a circle and that the boundary can be computed in polynomial time.
"
1985,Automatic surface generation in computer aided design.,"A technique for smoothly blending algebraic surfaces and a language for syntactic specification of objects are developed. Their use in automated design is illustrated by a gate valve example in which all fillets, edge roundings and joining surfaces are automatically constructed. The resulting object has an internal representation that is particularly amenable to interactive editing.
"
1985,"Representation, manipulation, and reasoning about physical objects.",n/a
1984,Movement Problems for 2-Dimensional Linkages.,"This paper is motivated by questions concerning the planning of motion in robotics. In particular, it is concerned with the motion of planar linkages from the complexity point of view. There are two main results. First, a planar linkage can be constrained to stay inside a bounded region whose boundary consists of straight lines by the addition of a polynomial number of new links. Second, the question of whether a planar linkage in some initial configuration can be moved so that a designated joint reaches a given point in the plane is PSPACE-hard."
1982,Fast Parallel Matrix and GCD Computations.,"Parallel algorithms to compute the determinant and characteristic polynomial of matrices and the gcd of polynomials are presented. The rank of matrices and solutions of arbitrary systems of linear equations are computed by parallel Las Vegas algorithms. All algorithms work over arbitrary fields. They run in parallel time O(log2 n) (where n is the number of inputs) and use a polynomial number of processors.
"
1982,On Edge Coloring Bipartite Graphs.,The present paper shows how to find a minimal edge coloring of a bipartite graph with E edges and V vertices in time $O(E\log V)$.
1982,Fast Parallel Matrix and GCD Computations.,"Abstract:
We present parallel algorithms to compute the determinant and characteristic polynomial of n√ón-matrices and the gcd of polynomials of degree ‚â§n. The algorithms use parallel time O(log2n) and a polynomial number of processors. We also give a fast parallel Las Vegas algorithm for the rank of matrices. All algorithms work over arbitrary fields."
1982,On the Movement of Robot Arms in 2-Dimensional Bounded Regions.,"Abstract:
The classical mover's problem is the following: can a rigid object in 3-dimensional space be moved from one given position to another while avoiding obstacles? It is known that a more general version of this problem involving objects with movable joints is PSPACE-complete, even for a simple tree-like structure. In this paper, we investigate a 2-dimensional mover's problem in which the object being moved is a robot arm with an arbitrary number of joints. We reduce the mover's problem for arms constrained to move within bounded regions whose boundaries are made up of straight lines to the mover's problem for a more complex linkage that is not constrained. We prove that the latter problem is PSPACE-hard even in 2-dimensional space and then turn to special cases of the mover's problem for arms. In particular, we give a polynomial time algorithm for moving an arm confined within a circle from one given configuration to another. We also give a polynomial time algorithm for moving the arm from its initial position to a position in which the end of the arm reaches a given point within the circle."
1982,"Routing, Merging and Sorting on Parallel Models of Computation (Extended Abstract).","A variety of models have been proposed for the study of synchronous parallel computation. We review these models and study further some prototype problems. We distinguish two classes of models, fixed connection networks and models based on a shared memory. Routing is the prototype problem for the networks. In particular, routing provides the basis for simulating the more powerful shared memory models. We show that a simple but important class of deterministic strategies (oblivious routing) is necessarily inefficient with respect to worst case analysis. Routing can be viewed as a special case of sorting and the existence of a deterministic O(logn) routing or sorting algorithm for an n processor fixed connection network remains open. However, if we consider the more powerful class of shared memory models, we are -&-ldquo;almost-&-rdquo; able to achieve such an efficient sort via Valiant's parallel merging algorithm. Within a spectrum of models, we show that log log n - log log r is asymptotically optimal for rn processors to merge two sorted lists of n elements."
1981,Recent Directions in Algorithmic Research.,n/a
1980,The Directed Subgraph Homeomorphism Problem.,"The set of pattern graphs for which the fixed directed subgraph homeomorphism problem is NP-complete is characterized. A polynomial time algorithm is given for the remaining cases. The restricted problem where the input graph is a directed acyclic graph is in polynomial time for all pattern graphs and an algorithm is given.
"
1980,Polynomial-Time Algorithms for Permutation Groups.,"Abstract:
A permutation group on n letters may always be represented by a small set of generators, even though its size may be exponential in n. We show that it is practical to use such a representation since many problems such as membership testing, equality testing, and inclusion testing are decidable in polynomial time. In addition, we demonstrate that the normal closure of a subgroup can be computed in polynomial time, and that this proceaure can be used to test a group for solvability. We also describe an approach to computing the intersection of two groups. The procedures and techniques have wide applicability and have recently been used to improve many graph isomorphism algorithms."
1979,A Note on Rabin's Nearest-Neighbor Algorithm.,n/a
1979,On the Reachability Problem for 5-Dimensional Vector Addition Systems.,"The reachability sets for vector addition systems of dimension less than or equal to five are shown to be effectively computable semilinear sets. Thus reachability, equivalence and containment are decidable up to dimension 5. An example of a non-semilinear reachability set is given for dimension 6.
"
1978,The Complexity of Equivalence and Containment for Free Single Variable Program Schemes.,"Abstract
Non-containment for free single variable program schemes is shown to be NP-complete. A polynomial time algorithm for deciding equivalence of two free schemes, provided one of them has the predicates appearing in the same order in all executions, is given. However, the ordering of a free scheme is shown to lead to an exponential increase in size."
1977,On Time Versus Space.,"It is shown that every deterministic multitape Turing machine of time complexity t(n) can be simulated by a deterministic Turing machine of tape complexity t(n)/logt(n). Consequently, for tape constructable t(n), the class of languages recognizable by multitape Turing machines of time complexity t(n) is strictly contained in the class of languages recognized by Turing machines of tape complexity t(n). In particular the context-sensitive languages cannot be recognized in linear time by deterministic multitape Turing machines."
1976,On Finding Lowest Common Ancestors in Trees.,"Trees in an n-node forest are merged according to instructions in a given sequence, while other instructions in the sequence ask for the lowest common ancestor of pairs of nodes. We show that any sequence of $O(n)$ such instructions can be processed ìon-lineî in $O(n\log n)$ steps on a random access computer.

If we can accept our answer ìoff-lineî, that is, no answers need to be produced until the entire sequence of instructions has been seen, then we may perform the task in $O(n\alpha (n))$ steps, where $\alpha (n)$ is the very slowly growing inverse Ackermann function defined in [14].

A third algorithm solves a problem of intermediate complexity. We require the answers on-line, but we assume that all tree merging instructions precede the information requests. This algorithm requires $O(n \log \log n)$ time.

We apply the first on-line algorithm to a problem in code optimization, that of computing immediate dominators in a reducible flow graph. We show how this computation can be performed in $O(n\log n)$ steps."
1975,On Time versus Space and Related Problems.,"It is shown that every deterministic multitape Turing machine of time complexity t(n) can be simulated by a deterministic Turing machine of tape complexity t(n)/logt(n). Consequently, for tape constructable t(n), the class of languages recognizable by mul"
1974,Efficient Planarity Testing.,"This paper describes an efficient algorithm to determine whether an arbitrary graph G can be embedded in the plane. The algorithm may be viewed as an iterative version of a method originally proposed by Auslander and Parter and correctly formulated by Goldstein. The algorithm used depth-first search and has O(V) time and space bounds, where V is the number of vertices in G. An ALGOL implementation of the algorithm succesfully tested graphs with as many as 900 vertices in less than 12 seconds."
1974,Complexity of Computer Computations.,n/a
1974,Linear Time Algorithm for Isomorphism of Planar Graphs (Preliminary Report).,"The isomorphism problem for graphs G1 and G2 is to determine if there exists a one-to-one mapping of the vertices of G1 onto the vertices of G2 such that two vertices of G1 are adjacent if and only if their images in G2 are adjacent. In addition to determining the existence of such an isomorphism, it is useful to be able to produce an isomorphism-inducing mapping in the case where one exists. The isomorphism problem for triconnected planar graphs is particularly simple since a triconnected planar graph has a unique embedding on a sphere [6]. Weinberg [5] exploited this fact in developing an algorithm for testing isomorphism of triconnected planar graphs in O(|V|2) time where V is the set consisting of the vertices of both graphs. The result has been extended to arbitrary planar graphs and improved to O(|V|log|V|) steps by Hopcroft and Tarjan [2,3]. In this paper, the time bound for planar graph isomorphism is improved to O(|V|). In addition to determining the isomorphism of two planar graphs, the algorithm can be easily extended to partition a set of planar graphs into equivalence classes of isomorphic graphs in time linear in the total number of vertices in all graphs in the set. A random access model of computation (see Cook [1]) is assumed. Although the proposed algorithm has a linear asymptotic growth rate, at the present stage of development it appears to be inefficient on account of a rather large constant. This paper is intended only to establish the existence of a linear algorithm which subsequent work might make truly efficient."
1973,Efficient Algorithms for Graph Manipulation [H] (Algorithm 447).,"Efficient algorithms are presented for partitioning a graph into connected components, biconnected components and simple paths. The algorithm for partitioning of a graph into simple paths of iterative and each iteration produces a new path between two vertices already on paths. (The start vertex can be specified dynamically.) If V is the number of vertices and E is the number of edges, each algorithm requires time and space proportional to max (V, E) when executed on a random access computer."
1973,A V log V Algorithm for Isomorphism of Triconnected Planar Graphs.,"An algorithm for determining whether two triconnected planar graphs are isomorphic is presented. The asymptotic growth rate of the algorithm is bounded by a constant times |V| log |V| where |V| is the number of vertices in the graphs.
"
1973,Dividing a Graph into Triconnected Components.,"An algorithm for dividing a graph into triconnected components is presented. When implemented on a random access computer, the algorithm requires $O(V + E)$ time and space to analyze a graph with V vertices and E edges. The algorithm is both theoretically optimal to within a constant factor and efficient in practice."
1973,Duality Applied to the Complexity of Matrix Multiplication and Other Bilinear Forms.,"The paper considers the complexity of bilinear forms in a noncommutative ring. The dual of a computation is defined and applied to matrix multiplication and other bilinear forms. It is shown that the dual of an optimal computation gives an optimal computation for a dual problem. An $n \times m$ by $m \times p$ matrix product is shown to be the dual of an $n \times p$ by $p \times m$ or an $m \times n$ by $n \times p$ matrix product, implying that each of the matrix products requires the same number of multiplications to compute. Finally, an algorithm for computing a single bilinear form over a noncommutative ring with a minimum number of multiplications is derived by considering a dual problem."
1973,An n5/2 Algorithm for Maximum Matchings in Bipartite Graphs.,The present paper shows how to construct a maximum matching in a bipartite graph with n vertices and m edges in a number of computation steps proportional to $(m + n)\sqrt n $.
1973,Set Merging Algorithms.,"This paper considers the problem of merging sets formed from a total of n items in such a way that at any time, the name of a set containing a given item can be ascertained. Two algorithms using different data structures are discussed. The execution times of both algorithms are bounded by a constant times $nG(n)$, where $G(n)$ is a function whose asymptotic growth rate is less than that of any finite number of logarithms of n."
1973,Duality Applied to the Complexity of Matrix Multiplications and other Bilinear Forms.,The paper considers the complexity of bilinear forms in a noncommutative ring. The dual of a computation is defined and applied to matrix multiplication and other bilinear forms. It is shown that the dual of an optimal computation gives an optimal computation for a dual problem. An nxm by mxp matrix product is shown to be the dual of an nxp by pxm or an mxn by nxp matrix product implying that each of the matrix products requires the same number of multiplications to compute. Finally an algorithm for computing a single bilinear form over a noncommutative ring with a minimum number of multiplications is derived by considering a dual problem.
1973,On Finding Lowest Common Ancestors in Trees.,"Trees in an n node forest are to be merged according to instructions in a given sequence, while other instructions in the sequence ask for the lowest common ancestor of pairs of nodes. We show that any sequence of O(n) instructions can be processed ‚Äúon line‚Äù in O(n log n) steps on a random access computer. If we can accept our answer ‚Äúoff-line‚Äù, that is, no answers need to be produced until the entire sequence of instructions has been seen seen, then we may perform the task in O(n G(n)) steps, where G(n) is the number of times we must apply log2 to n to obtain a number less than or equal to zero. A third algorithm solves a problem of intermediate complexity. We require the answers on line, but we suppose that all tree merging instructions precede the information requests. This algorithm requires O(n log log n) time. We apply the first on line algorithm to a problem in code optimization, that of computing immediate dominators in a reducible flow graph. We show how this computation can be performed in O(n log n) steps."
1972,Isomorphism of Planar Graphs.,"Abstract
An algorithm is presented for determining whether or not two planar graphs are isomorphic. The algorithm requires O(V log V) time, if V is the number of vertices in each graph."
1971,A V≤ Algorithm for Determining Isomorphism of Planar Graphs.,n/a
1971,An Overview of the Theory of Computational Complexity.,"The purpose of this paper is to outline the theory of computational complexity which has emerged as a comprehensive theory during the last decade. This theory is concerned with the quantitative aspects of computations and its central theme is the measuring of the difficulty of computing functions. The paper concentrates on the study of computational complexity measures defined for all computable functions and makes no attempt to survey the whole field exhaustively nor to present the material in historical order. Rather it presents the basic concepts, results, and techniques of computational complexity from a new point of view from which the ideas are more easily understood and fit together as a coherent whole."
1971,Images of AFL under Certain Families of Homomorphisms.,"Abstract
An AFL is a family of sets of words closed under six basic operations. It is shown that a certain family of homomorphic images of sets in an AFL is an AFL. Then two families of sets related to tape-bounded nondeterministic Turing acceptors are shown to coincide and be an AFL."
1971,A n^5/2 Algorithm for Maximum Matchings in Bipartite Graphs.,"Abstract:
The present paper shows how to construct a maximum matching in a bipartite graph with n vertices and m edges in a number of computation steps proportional to (m+n) n."
1971,Planarity Testing in V log V Steps: Extended Abstract.,"An efficient algorithm is presented for determining whether or not a given graph is planar. If V is the number of vertices in the graph, the algorithm requires time proportional to V log V and space proportional to V when run on a random-access computer. The algorithm constructs the facial boundaries of a planar representation without backup, using extensive list-processing features to speed computation. The theoretical time bound improves on that of previously published algorithms. Experimental evidence indicates that graphs with a few thousand edges can be tested within seconds"
1970,Two-way balloon automata and AFL.,"It is shown that if the family of languages accepted by a closed class of two-way balloon automata is closed under length-preserving homomorphism, then this family is an AFL closed under intersection and e-free substitution. It is then proved that the family of languages accepted by the closed class of two-way balloon automata of (nonerasing) (deterministic) stack acceptors is such a family."
1970,On the Computational Power of Pushdown Automata.,"We present a relation between the sets accepted by two-way pushdown automata and certain tape complexity classes of off-line Turing machines. Specifically, let L be a language accepted by a nondeterministic off-line Turing machine T. Let T have a t-symbol storage-tape alphabet. If for all but a finite number of n, T uses no more than log2tn storage cells when given an input of length n, then L is accepted by a twoway nondeterministic pushdown automaton. Thus, any nondeterministic tape complexity class L(n) such that supn??(L(n)/logn))=0 is a subfamily of the two-way nondeterministic pushdown automaton languages.
"
1970,What makes Some Language Theory Problems Undecidable.,"In the theory of automata and formal languages, the undecidability of various properties has been studied for specific classes of languages. Here we abstract the essence of various proofs of undecidability and find wide classes of properties and general conditions on families of languages such that these proofs of undecidability hold. The paper also illustrates the manner in which the degree of undecidability of a property changes as we consider more and more complicated families of languages.
"
1970,R70-2 Nested Stack Automata.,"Abstract:
A nested stack automaton is a generalization of the pushdown automaton. Basically, the nested stack automaton consists of an input tape, a finite control, and a single pushdown list. However, the nested stack automaton can access symbols in the interior of the stack in a read-only mode and create new stacks nested (to arbitrary depths) within the main stack, subject to the restriction that the stack head may not move up a stack without first having destroyed all stacks created at that level. The importance of the model is that the class of languages accepted is precisely the indexed languages. The indexed languages have most of the properties of the context- free languages, i.e., derivation trees, recursiveness, decidable emptiness problem, closed under concatenation, Kleene closure, homomorphisms, inverse homomorphisms, and intersection with regular sets. Furthermore, the indexed grammars are capable of exhibiting syntactic features in algorithmic programming languages not representable by context-free grammars."
1969,Some Results on Tape-Bounded Turing Machines.,"Classes of tape-bounded Turing machines similar to the on-line and off-line Turing machines, but without the restrictions that each machine halt and be deterministic, are studied. It is shown that the lower bounds on tape complexity of [1] depend on neither the halting assumption nor determinism. The existence of a dense hierarchy of complexity classes likewise does not depend on the halting assumption, and it is shown that below log n tape complexity there exists a dense hierarchy of complexity classes for two-way nondeterministic devices. It is also shown that the complexity classes of one-way, nondeterministic machines below linear large complexity are not closed under complementation and are larger that the corresponding deterministic complexity class."
1969,Scattered Context Grammars.,"Scattered context grammars are defined and the closure properties of the family of languages generated are considered. This family of languages is contained in the family of context sensitive languages and contains all languages accepted by linear time nondeterministic Turing machines.
"
1969,On the Equivalence and Containment Problems for Context-Free Languages.,"Let G and G0 be context-free grammars. Necessary and sufficient conditions on G0 are obtained for the decidability of L(G0)  ? L((G) It is also shown that it is undecidable for which G0,L(G)  ?  is decidable. Furthermore, given that L(G)  ?  is decidable for a fixed G0, there is no effective procedure to determine the algorithm which decides L(G)  ?  If L(G0) is a regular set,L(G) = L(G0) is decidable if and only if L(G0) is bounded. However, there exist non-regular, unbounded L(G0) for which L(G) = L(G0) is decidable.
"
1969,A General Theory of Translation.,"The concept of a translation is fundamental to any theory of compiling. Formally, a translation is any set of pairs of words. Classes of finitely describable translations are considered in general, from the point of view of balloon automata [17, 18, 19].
A translation can be defined by a transducer, a device with an input tape and an output terminal. If, with input x, the string y appears at the output terminal, then (x, y) is in the translation defined by the transducer. One can also define a translation by a two input tape recognizer. Ifx and y are placed on the two tapes, the recognizer tells if (x, y) is in the defined translation. One can define closed classes of transducers and recognizers by: restricting the way in which infinite storage may be used (pushdown structure, stack structure, etc.), allowing the finite control to be nondeterministic or deterministic,
allowing one way or two way motion on the input tapes.
We have some results on classes of translations which can be categorized roughly into three types. Translations defined by certain classes of transducers and recognizers are equivalent.
Translations of a given class are sometimes closed under composition and decomposition with a finite memory translation (gsm mapping).
A nondeterministically defined translation can be expressed as the composition of a finitely defined translation and a related deterministically defined translation in many cases.
In addition, if C is a class of translations, then one can write a compiler-compiler to render any translation T in C and only if the following question is solvable: For any translation T in C and string x, does there exist ay such that (x, y) is inT? We shall show that, in general, the decidability of this question is equivalent to the decidability of one or more questions from automata theory, depending upon the type of devices defining the class C.


"
1969,Dense and Non-Dense Families of Complexity Classes.,"Abstract:
Let Œ¶ be any abstract measure of computational complexity, and let L denote the specific measure of memory resource (tape) on one tape Turing machines. Denote by Rt( )Œ¶ the class of all total functions whose Œ¶-complexity is bounded by the function t( ) almost everywhere. Call such classes Œ¶-complexity classes. We are interested in relationships among these classes, under proper set inclusion (‚äÇ). In other words, we are interested in the partially ordered structure ‚â™ Œ£Œ¶,‚äÜ ‚â´ where Œ£Œ¶ = {Rt( )Œ¶|t( ) is recursive} is called the family of Œ¶-complexity classes. Of special interest is the subfamily Œ©Œ¶ = {RŒ¶i( )Œ¶ | Œ¶i( ) is total}, called the family of exact Œ¶-complexity classes. We show that Œ£L and Œ©L are dense under ‚äÇ for sufficiently large bounds t( ), but Œ©L is not dense in Œ£L. We also construct measures Œ¶ for which Œ£Œ¶ and Œ©Œ¶ are non-dense, for which Œ£Œ¶ is dense but Œ©Œ¶ is not, for which Œ©Œ¶ is dense but Œ£Œ¶ is not and for which Œ©Œ¶ is dense in Œ£Œ¶. Thus density is not a measure invariant property of Œ£Œ¶ or Œ©Œ¶. These are the first examples of important structural properties of these families which are not measure invariant."
1969,Some Techniques for Proving Certain Simple Programs Optimal.,"Abstract:
This paper develops techniques for establishing a lower bound on the number of arithmetic operations necessary for sets of simple expressions. The techniques are applied to matrix multiplication. A modification of Strassen's algorithm is developed for multiplying n √ó p matrices by p √ó q matrices. The techniques are used to prove that this algorithm minimizes the number of multiplications for a few special cases. In so doing we establish that matrix multiplication with elements from a commutative ring requires fewer multiplications than with elements from a non-commutative ring."
1968,Sets Accepted by One-Way Stack Automata Are Context Sensitive.,"A stack automaton is a pushdown automaton that can read the interior of its pushdown list without altering it.
It is shown that a nondeterministic stack automation with a one-way input tape can be simulated by a deterministic linear bounded automaton. Hence, each nondeterministic one-way stack language is context sensitive.
"
1968,Time and Tape Complexity of Pushdown Automaton Languages.,"An algorithm is presented which will determine whether any string w in ?*, of length n, is contained in a language L ? ?* defined by a two-way nondeterministic pushdown automation. This algorithm requires time n3 when implemented on a random access computer. It requires n4 time and n2 tape when implemented on a multitape Turing machine.
If the pushdown automaton is deterministic, the algorithm requires n2 time on a random access computer and n2 log n time on a multitape Turing machine.
"
1968,Decidable and Undecidable Questions About Automata.,"Four types of balloon automata (defined by one- or two-way input and deterministic or nondeterministic finite control) and closed classes of balloon automata were previously defined by the authors. A set of closed classes, one for each of the four types, is called a family if the classes use their infinite storage in the same way. The recursiveness and solvability of the emptiness problem for closed classes are investigated in the present paper. It is shown that in many cases the solvability of one of these questions for one closed class in a family implies that some other question are solvable for the closed classes of that family."
1968,Relations Between Time and Tape Complexities.,"It is shown that if a language L is recognized by a (nondeterministic) single-tape Turing machine of time complexity T(n), then L is recognized by a (nondeterministic) offline Turing machine of tape complexity T1/2(n). If T(n) ‚â• n2;, L is recognized by a (nondeterministic) single-tape Turing machine of tape complexity T1/2(n). If a language L is recognized by a (nondeterministic) offline Turing machine of time complexity (T(n), then L is recognized by a (nondeterministic) offline Turing machine of tape complexity (T(n) log n)1/2 and by a (nondeterministic) single-tape Turing machine of that tape complexity if T (n) ‚â• n2/log n."
1968,Deterministic Stack Automata and the Quotient Operator.,"A stack automaton is a pushdown automaton with the added privilege of scanning the contents of its pushdown tape without erasing. In this paper, the deterministic stack automaton with a one-way input (dsa) is considered.
It is shown that if L is a language accepted by a dsa and R is a regular set, then L/R={w| for some x in R, wx is in L}, is accepted by a dsa. As a corollary, end markers are not needed on the input of the dsa. It is also shown that if L is accepted by a dsa, then Max(L)={w|w in L and for no x is wx is wx in L} is accepted by a dsa.
"
1968,Two-Way Balloon Automata and AFL.,"Abstract:
It is shown that if the family of languages accepted by a closed class of two-way balloon automata is closed under length-preserving homomorphism, then this family is an AFL closed under intersection and Œµ-free substitution. It is then proved that the family of languages accepted by the closed class of (nonerasing) (deterministic) stack acceptors is such a family."
1968,Structure of Undecidable Problems in Automata Theory.,"Abstract:
The purpose of this paper is to gain a better understanding of the structure of undecidable problems in automata theory by investigating the degree of unsolvability of these problems. This is achieved by using Turing machines with oracles to define when one undecidable problem can be reduced to another and to establish an infinite hierarchy of (equivalent) undecidable problems. This hierarchy is then used to classify well-known undecidable problems about various families of automata and formal languages and to study the relations between these problems. This approach reveals a well defined structuring of the undecidable problems and permits a more systematic study of these problems and their relation to various families of automata."
1968,Scattered context grammars.,Scattered context grammars are defined and the closure properties of the family of languages generated are considered. This family of languages is contained in the family of context sensitive languages and contains all languages accepted by linear time nondeterministic Turing machines. 
1967,Nonerasing Stack Automata.,"The stack automaton has been recently introduced into the literature as a model for a compiler. The stack automaton has a two-way input tape, a finite control and a stack. The stack is similar to a push-down store, in that writing and erasing occur only at the top. However, the stack head may also move up or down the stack in a read only mode.
Here, nonerasing stack automata only, are considered. These are stack automata that never erase a symbol from their stack. It is shown that the deterministic, nonerasing stack automaton is equivalent to a deterministic, off-line Turing machine whose storage tape never grows beyond n log2n cells where n is the length of the input. Also, it is shown that the nondeterministic, nonerasing stack automaton is equivalent to a nondeterministic off-line Turing machine whose tape never grows beyond n2 cells.
"
1967,Two Results on One-Way Stack Automata.,"Abstract:
A stack automaton is a device with a pushdown list which can be read by its storage head in a read only mode. In this paper, we show two properties of stack automata with a one-way input. (1) If a language is accepted by a nondeterministic one-way stack automaton, then it is accepted by a deterministic linear bounded automaton. (2) If a language, L, is accepted by a deterministic one-way stack automaton, and R is a regular set, then L/R = {x for some y in R, xy is in L} is accepted by a deterministic one-way stack automaton."
1967,An Approach to a Unified Theory of Automata.,"Abstract:
An automaton called the balloon automaton is defined. The balloon automaton comes in four varieties, depending on whether the device is deterministic or nondeterministic, and whether the input head can move in one or two directions. Subsets of the balloon automata of each variety, called closed classes are defined. Almost all the known types of automata are equivalent to some closed class of balloon automata. Properties of closed classes are given. For example, whatever the variety, the languages accepted by a closed class are closed under intersection with a regular set. For a given organization of storage, closed classes of the four varieties can be defined. These four classes are said to form a family. A class may be recursive or not, and the emptiness problem may be solvable or unsolvable. Some surprising relationships exist between the recursiveness and solvability of emptiness for the classes in a family."
1967,Modular Decomposition of Synchronous Sequential Machines.,"Abstract:
In this paper we are concerned with the decomposition of synchronous sequential machines into interconnections of component machines. The term interconnection is taken literally; the input terminals of a component machine must be directly connected to either i) a logical constant, ii) an output terminal of a component machine, or iii) an external input line. A fundamental question regarding such decompositions is ""Does there exist a finite set of component machines such that any given machine can be realized by an interconnection of copies of the component machines?"" The answers to this and related questions comprise the scope of the paper."
1966,Encoding of analog signals for binary symmetric channels.,"Abstract:
Various encoding schemes are examined from the point of view of minimizing the mean magnitude error of a signal caused by transmission through a binary symmetric channel. A necessary property is developed for optimal codes for any binary symmetric channel and any set of quantization levels. The class of optimal codes is found for the case where the probability of error is small but realistic. This class of codes includes the natural numbering and some unit distance codes, among which are the Gray codes."
1966,Simple Deterministic Languages.,"Abstract:
The s-languages are those languages recognized by a particular restricted form of deterministic pushdown automaton, called an s-machine. They are uniquely characterized by that subset of the standard-form grammars in which each rule has the form Z ‚Üí aY1...Yn, n‚â•0, and for which the pairs (Z, a) are distinct among the rules. It is shown that the s-languages have the prefix property, and that they include the regular sets with end-markers. Finally, their closure properties and decision problems are examined, and it is found that their equivalence problem is solvable. Since the solvability of the equivalence problem is not known for arbitrary deterministic languages, the s-languages are the most general class of languages for which this problem has been shown to be solvable."
1965,Synthesis of Minimal Threshold Logic Networks.,"Abstract:
An algorithm is developed for synthesizing networks which realize Boolean switching functions through the use of a minimum number of threshold logic elements. A switching function is represented by a matrix and the algorithm is based on the principle that the removal of the positive linear dependences from the rows of this matrix results in a linearly separable function. The positive linear dependences are removed by adding columns to the matrix, each column representing the output of a threshold logic element in the network. The added columns in effect transform a nonseparable function into a sparable function a higher dimensional space. The algorithm is illustrated with examples of the synthesis of both single and multiple output networks. The technique is not restricted to completely specified functions."
