2019,Mutual Exclusion Sizing for Hoi Polloi.,"Abstract:
Granting access to a shared self-timed resource requires a mutual exclusion circuit to resolve contention. All such circuits contain cross-coupled logic gates to decide contested cases on a first-come-first-served basis. An end-of-metastability detector grants a decision only after metastability, if any, ends. This brief contrasts two previously published mutual exclusion designs and offers previously unavailable guides to achieving least uncontested grant delay for each design. The faster design integrates its cross-coupled gates and end-of-metastability detector into a single stage. The slower design pays a time penalty by isolating these two functions in separate sequential logic stages."
2019,A Hierarchical Approach to Self-Timed Circuit Verification.,"Abstract:
Self-timed circuits can be modeled in a link-joint style using a formally defined hardware description language. It has previously been shown how functional properties of these models can be formally verified with the ACL2 theorem prover using a scalable, hierarchical method. Here we extend that method to parameterized circuit families that may have loops and non-deterministic outputs. We illustrate this extension with iterative self-timed circuits that calculate the greatest common divisor of two natural numbers, with circuits that perform arbitrated merges non-deterministically, and with circuits that combine both of these."
2018,Data-Loop-Free Self-Timed Circuit Verification.,"Abstract:
This paper presents a methodology for formally verifying the functional correctness of self-timed circuits whose data flows are free of feedback loops. In particular, we formalize the relationship between their input and output sequences. We use the DE system, a formal hardware description language built using the ACL2 theorem-proving system, to specify and verify finite-state-machine representations of self-timed circuit designs. We apply a link-joint paradigm to model self-timed circuits as networks of computations that communicate with each other with protocols. Our approach exploits hierarchical reasoning and induction to support scalability. We demonstrate our methodology by modeling and verifying several data-loop-free self-timed circuits."
2017,How to think about self-timed systems.,"Abstract:
Self-timed systems divide nicely into two kinds of components: communication links that transport and store data, and computation joints that apply logic to data. We treat these two types of self-timed components as equally important. Putting communication on a par with computation acknowledges the increasing cost of data transport and storage in terms of energy, time, and area. Our clean separation of data transport and storage from logic simplifies the design and test of self-timed systems. The separation also helps one to grasp how self-timed systems work. We offer this paper in the hope that better understanding of self-timed systems will engage the minds of compiler, formal verification, and test experts."
2017,A Framework for Asynchronous Circuit Modeling and Verification in ACL2.,"Abstract
Formal verification of asynchronous circuits is known to be challenging due to highly non-deterministic behavior exhibited in these systems. One of the main challenges is that it is very difficult to come up with a systematic approach to establishing invariance properties, which are crucial in proving the correctness of circuit behavior. Non-determinism also results in asynchronous circuits having a complex state space, and hence makes the verification task much more difficult than in synchronous circuits. To ease the verification task by reducing non-determinism, and consequently reducing the complexity of the set of execution paths, we impose design restrictions to prevent communication between a module M and other modules while computations are still taking place that are internal to M. These restrictions enable our verification framework to verify loop invariants efficiently via induction and subsequently verify the functional correctness of asynchronous circuit designs. We apply a link-joint paradigm to model asynchronous circuits. Our framework applies a hierarchical verification approach to support scalability. We demonstrate our framework by modeling and verifying the functional correctness of a 32-bit asynchronous serial adder."
2016,Modular Timing Constraints for Delay-Insensitive Systems.,"This paper introduces ARCtimer, a framework for modeling, generating, verifying, and enforcing timing constraints for individual self-timed handshake components. The constraints guarantee that the componentís gate-level circuit implementation obeys the componentís handshake protocol specification. Because the handshake protocols are delayinsensitive, self-timed systems built using ARCtimer-verified components are also delay-insensitive. By carefully considering time locally, we can ignore time globally. ARCtimer comes early in the design process as part of building a library of verified components for later system use. The library also stores static timing analysis (STA) code to validate and enforce the componentís constraints in any self-timed system built using the library. The library descriptions of a handshake componentís circuit, protocol, timing constraints, and STA code are robust to circuit modifications applied later in the design process by technology mapping or layout tools. In addition to presenting new work and discussing related work, this paper identifies critical choices and explains what modular timing verification entails and how it works.
"
2015,Naturalized Communication and Testing.,"Abstract:
We ""naturalize"" the handshake communication links of a self-timed system by assigning the capabilities of filling and draining a link and of storing its full or empty status to the link itself. This contrasts with assigning these capabilities to the joints, the modules connected by the links, as was previously done. Under naturalized communication, the differences between Micropipeline, GasP, Mousetrap, and Click circuits are seen only in the links -- the joints become identical; past, present, and future link and joint designs become interchangeable. We also ""naturalize"" the actions of a self-timed system, giving actions status equal to states -- for the purpose of silicon test and debug. We partner traditional scan test techniques dedicated to state with new test capabilities dedicated to action. To each and every joint, we add a novel proper-start-stop circuit, called MrGO, that permits or forbids the action of that joint. MrGO, pronounced ""Mister GO,"" makes it possible to (1) exit an initial state cleanly to start circuit operation in a delay-insensitive manner, (2) stop a running circuit in a clean and delay-insensitive manner, (3) single- or multi-step circuit operations for test and debug, and (4) test sub-systems at speed."
2012,The tyranny of the clock.,Promoting a clock-free paradigm that fits everything learned about programming since Turing.
2012,Computer Architecture.,"Sixty-five years ago, Alan Turing produced a proposal for the construction of a general-purpose computer, the Automatic Computing Engine, or ACE. Subsequently built at the U.K. National Physical Laboratory, it was briefly the fastest computer in the world. Although its architecture was quite different from the arrangement proposed by Von Neumann and others that eventually came to dominate the computing landscape, examining it gives us a chance to understand some of the tradeoffs that early computer architects explored.
The panel will examine the ACE to provide a setting for the discussions that follow, in which they will explore some of the architectural tradeoffs that have been made in the past, are still being made today, and which will shape the direction of computing in the future. What would Alan Turing have thought about the impact that computers have had on society? What would he have thought about the warehouse-scale computing that makes possible a realization of Vannevar Bush's 1945 Memex vision? What about the possibility of quantum computing? The panelists will discuss these topics as well as the progress and future of academic computer architecture research."
2011,Self-timing: a step beyond synchrony (tutorial talk).,"Each part of a self-timed system starts work as soon as all its inputs are available, taking whatever time it needs to do its job and signaling when it is done. Each part waits for its predecessors to finish. The parts operate concurrently but not synchronously. Self-timed systems use local timing signals rather than a global clock
Self-timing eliminates the rigidity and energy consumption of a global clock. Self-timed systems operate over a wide range of power supply voltage. They automatically go slower at reduced voltage, saving energy both from lower voltage and from reduced speed. Their power-saving properties are making them increasingly attractive.
The design challenge posed by self-timing is the subject of this tutorial. Self-timed systems need the usual proofs of logical correctness. In addition, because they can take advantage of average rather than worst-case delay, analysis of circuit delay based on data statistics will be important. Of course, it's essential to check the timing of local signals, but commercial timing tools all check timing against a global ""clock"" signal that's absent from self-timed systems. Instead, self-timing focuses attention on the relative timing of pairs of signals. Self-timed systems pose all the elusive problems of concurrency: deadlock, non-determinism, and arbitration."
2011,The sequential prison.,"We are trapped in a sequential prison. We use sequential character strings to write sequential programs to control sequential computers. No wonder concurrency remains elusive. How did we come to be here? The high cost of vacuum tube logic forced sequence upon early computer builders. Sequential character strings were the economic way to describe what sequential computers should do. Sequential programs controlled the expensive part of the machine, namely logic. The lethargic pace of logic circuits masked the cost of moving data over distance, allowing programming languages to ignore the cost of communication. Today, the time delay and energy cost of communicating over distance dominate modern computers; logic is essentially free. Why then, do programming languages continue to control logic and largely ignore communication? It will take a broad effort to escape our sequential prison, requiring changes in hardware, programming notations and the ways in which they are expressed. Most importantly, it will require recognizing that we are in sequential prison, and planning for an escape."
2010,Long-Range GasP with Charge Relaxation.,"Abstract:
GasP circuit modules communicate handshake signals in two directions over a single state wire. The 2008 Infinity test chip demonstrated GasP in 90 nm CMOS operating at four giga data items per second, but revealed that state wires about 5000 lambda long retard operation by about 10%. Simulations reported in this paper show that GasP modules will tolerate surprisingly long state wires, albeit at reduced throughput. The modules appear to operate correctly with state wires whose delay exceeds the drive time. With such long wires, the receiving module waits until passive distribution of charge brings the wire within range of the receiver's switching threshold. Having put enough charge into the wire, or vice-versa removed enough charge from it,the sending module may proceed with its next task. This result applies equally to other single-track signaling methods.This behavior calls for a new kind of relative timing constraint to address when the wire charging or discharging process may cease rather than when the signal reaches the far end of the wire."
2010,Timing Verification of GasP Asynchronous Circuits: Predicted Delay Variations Observed by Experiment.,"Abstract
This paper reports spreadsheet calculations intended to verify the timing of 6-4 GasP asynchronous Network on Chip (NoC) control circuits. The Logical Effort model used in the spreadsheet estimates the delays of each logic gate in the GasP control. The calculations show how these delays vary in response to differing environmental conditions. The important environmental variable is the physical distance from one GasP module to adjacent modules because longer wires present greater capacitance that retards the operation of their drivers. Remarkably, the calculations predict correct operation over a large range of distances provided the difference in the distances to predecessor and successor modules is limited, and predict failure if the distances differ by too much. Experimental support for this view comes from the measured behavior of a test chip called ‚ÄúInfinity‚Äù built by Sun Microsystems in 90 nanometer CMOS circuits fabricated at TSMC."
2007,Circuit Techniques to Enable 430Gb/s/mm2 Proximity Communication.,"Abstract:
Two chips communicate over a capacitively-coupled I/O link at 1.8Gb/s/ch. Channels are placed on a 36mum pitch. 144 channels operate simultaneously for an aggregate bandwidth of 260Gb/s, or 430Gb/s/mm 2 in 0.18mum CMOS. Measured energy consumption is 3.0pJ/b and BER is <10 -15 . Electronic alignment and crosstalk rejection allow reliable I/O for practical implementation"
2005,Proximity Communication and Time.,"Abstract:
Summary form only given. Two IC chips placed face-to-face can communicate without direct electrical contact. The capacitive coupling between their top-level metal layers can carry data. We have demonstrated such ""proximity communication"" on 50 /spl mu/m centers and data rates similar to on-chip wires. Such communication offers attractive speed, density, and energy economy, but requires accurate mechanical alignment. Proximity communication requires sensitive amplifiers to compensate for the attenuation suffered as signals pass from one chip to the other. Signals with uncertain arrival times require an amplifier that can distinguish between signal and no signal. The difference between receiving attenuated data signals and receiving attenuated control signals focuses attention on the fundamental problem of time in asynchronous systems. This talk addresses the above issues."
2005,GasP Control for Domino Circuits.,"Abstract:
We present two novel asynchronous control circuits for domino pipelines. The control circuits are based on GasP circuits, have a minimum cycle time of six gate delays, and compare favorably with previously published control circuits. We present some results from a chip implementation of several 64-bit domino adders in a TSMC CMOS 180 nm process technology."
2005,Interaction at Lincoln laboratory in the 1960's: looking forward -- looking back.,"The activity centered around the TX-2 computer at Lincoln Laboratory in the 1960's laid the foundation for much of HCI. Through the use of archival film footage, and live presentations by some of the key protagonists, this panel is intended to contribute to a more general awareness of this work, its historical importance to HCI, and its relevance to research today."
2005,Challenges in Building a Flat-Bandwidth Memory Hierarchy for a Large-Scale Computer with Proximity Communication.,"Abstract:
Memory systems for conventional large-scale computers provide only limited bytes/s of data bandwidth when compared to their flop/s of instruction execution rate. The resulting bottleneck limits the bytes/flop that a processor may access from the full memory footprint of a machine and can hinder overall performance. This paper discusses physical and functional views of memory hierarchies and examines existing ratios of bandwidth to execution rate versus memory capacity (or bytes/flop versus capacity) found in a number of large-scale computers. The paper then explores a set of technologies, proximity communication, low-power on-chip networks, dense optical communication, and sea-of-any thing interconnect, that can flatten this bandwidth hierarchy to relieve the memory bottleneck in a large-scale computer that we call ""Hero""."
2001,GasP: A Minimal FIFO Control.,"Abstract:
The GasP family of asynchronous circuits provides controls for simple pipelines, for branching and joining pipelines, for round-robin scatter and gather for data dependent scatter and gather and for join on demand through arbitration. The family is designed so that each stage operates at the speed of a three-inverter ring oscillator Test chips in 0.35 micron technology exhibit throughput in excess of 1.5 giga data items per second (GDI/s). Between GasP pipeline stages a single wire carries both request and acknowledge messages, also recording the FULL or EMPTY state of each pipeline stage. GasP control circuits rely on careful choice of transistor widths to equalize the delay in logic gates. Assurance of uniform gate delays permits use of self-resetting logic forms that have very low logical effort."
2001,FLEETzero: An Asynchronous Switching Experiment.,"Abstract:
This paper describes a working chip, called FLEETzero, built to test an asynchronous switch fabric. The switch fabric transports 8-bit data items from any of eight sources to any of eight destinations. Measured throughput corresponds to approximately six gate-delays per data item, which in its 0.35 micron technology is in excess of 1.2 Giga-Data-Items per second (GDI/s); the corresponding latency through seven stages from source to destination is less than 4 nanoseconds. FLEETzero demonstrates a new family of high speed asynchronous control circuits, especially data-controlled branch and merge circuits that form the switch fabric. The FLEET concept may also herald a paradigm shift for computers. This new paradigm emphasizes data movement as the core action and contrasts with the traditional op code paradigm that focuses attention on logic and arithmetic instructions. The new paradigm promises outstanding throughput and many opportunities for optimization."
2001,Designing Fast Asynchronous Circuits.,"Abstract:
A five-step design process for asynchronous circuits helps simplify their logic and speed their operation. First, assume that all logic gates in the control will have nearly uniform delay. Second, use the uniform delay assumption to simplify control logic. Third, lay out the chip to get wire length data. Fourth, choose a specific delay and calculate transistor widths to apply that specific delay uniformly to all logic gates in the control; this paper shows how. Fifth, verify correct operation with standard methods. The specific gate delay trades off speed, area, and power consumption; postponing its choice takes advantage of asynchrony to accommodate the limitations imposed by layout. The theoretical lower bound for specific delay depends on the logical effort of the most complex loop in the design and remarkably, is independent of wire capacitance, given wide enough transistors, but wire capacitance puts practical bounds on speed. The effect of wire resistance remains unexplored."
1999,A Counterflow Pipeline Experiment.,"Abstract:
The counterflow pipeline architecture consists of two interacting pipelines in which data items flow in opposite directions. Interactions occur between two items when they meet in a stage. We present the design decisions for, and test measurements from, an asynchronous chip that explores the basic ideas of such an architecture. We built the chip in order to confirm proper operation of the arbiters required to ensure that each and every item flowing in one direction interacts with each and every item flowing in the other direction. Our chip, named ""Zeke,"" was built in 0.6 /spl mu/m CMOS through the MOSIS fabrication facility. The maximum total throughput of the chip, which is the sum of the throughputs of the two pipelines, varies between 491 MDI/s (mega data items per second) and 699 MDI/s, depending on the amount of interaction that takes place. Under average data and operating conditions the performance of our chip was roughly halfway between these throughput values."
1998,A FIFO Data Switch Design Experiment.,"Abstract:
A core problem in many pipelined circuit designs is data-dependent data flow. We describe a methodology and a set of circuit modules to address this problem in the asynchronous domain. We call our methodology P**3, or ""P cubed"". Items flowing through a set of FIFO datapaths can be conditionally steered under the control of data carried by other FIFOs. We have used the P**3 methodology to design and implement a FIFO rest chip that uses a data-dependent switch to delete marked data items conditionally. The circuit uses two on-chip FIFO rings as high-speed data sources. It was fabricated through MOSIS using their 0.6 /spl mu/ CMOS design rules. The peak data switch throughput was measured to be a minimum of 580 million data items per second at nominal Vdd of 3.3 V."
1998,Predicting Performance of Micropipelines Using Charlie Diagrams.,"Abstract:
A technique is presented to predict the performance behavior of control circuits for a linear FIFO. The control circuit consists of a linear chain of RendezVous elements, also called JOINs, preceded by a source and followed by a sink. The technique predicts how the cycle time, or throughput, of the FIFO depends on the sink delay, the source delay, and the length of the FIFO. It also predicts how the delays in each RendezVous element depend on the same set of parameters. The pipelines can be divided into three cases: source-limited, sink-limited, and self-limited pipelines. The technique is based on the assumption that the delays through a RendezVous element can be described as a function of the separation in arrival times of the inputs. Such descriptions are conveniently represented by the so-called Charlie diagram."
1994,The Counterflow Pipeline Processor Architecture.,"The counterflow pipeline processor architecture (CFPP) is a proposal for a family of microarchitectures for RISC processors. The architecture derives its name from its fundamental feature, namely that instructions and results flow in opposite directions within a pipeline and interact as they pass. The architecture seeks geometric regularity in processor chip layout, purely local control to avoid performance limitations of complex global pipeline stall signals, and simplicity that might lead to provably correct processor designs. Moreover, CFPP designs allow asynchronous implementations, in contrast to conventional pipeline designs where the synchronization required for operand forwarding makes asynchronous designs unattractive. This paper presents the CFPP architecture and a proposal for an asynchronous implementation. Detailed performance simulations of a complete processor design are not yet available."
1992,A Comparison of Codebook Generation Techniques for Vector Quantization.,"Abstract:
The paper examines tradeoffs between speed and quality of codebook/generation algorithms and offers new ways to produce excellent codebooks with only modest computation cost. It compares the performance of four algorithms for constructing codebooks. The LBG method of Linde, Buzo, and Gray (1980) produces the best codebooks but requires the most computation. The method by Equitz (1987, 1989) produces codebooks nearly as good and requires somewhat less computation. It describes a new method based on eigenvector subdivision that produces useable codebooks in a fraction of the computational effort of either of the other methods. A fourth hybrid method yields very good codebooks with modest computation by using the eigenvector subdivision method to obtain a first approximation that is refined with LBG optimization.< >"
1989,Micropipelines.,"The pipeline processor is a common paradigm for very high speed computing machinery. Pipeline processors provide high speed because their separate stages can operate concurrently, much as different people on a manufacturing assembly line work concurrently on material passing down the line. Although the concurrency of pipeline processors makes their design a demanding task, they can be found in graphics processors, in signal processing devices, in integrated circuit components for doing arithmetic, and in the instruction interpretation units and arithmetic operations of general purpose computing machinery. Because I plan to describe a variety of pipeline processors, I will start by suggesting names for their various forms. Pipeline processors, or more simply just pipelines, operate on data as it passes along them. The latency of a pipeline is a measure of how long it takes a single data value to pass through it. The throughput rate of a pipeline is a measure of how many data values can pass through it per unit time. Pipelines both store and process data; the storage elements and processing logic in them alternate along their length. I will describe pipelines in their complete form later, but first I will focus on their storage elements alone, stripping away all processing logic. Stripped of all processing logic, any pipeline acts like a series of storage elements through which data can pass. Pipelines can be clocked or event-driven, depending on whether their parts act in response to some widely-distributed external clock, or act independently whenever local events permit. Some pipelines are inelastic; the amount of data in them is fixed. The input rate and the output rate of an inelastic pipeline must match exactly. Stripped of any processing logic, an inelastic pipeline acts like a shift register. Other pipelines are elastic; the amount of data in them may vary. The input rate and the output rate of an elastic pipeline may differ momentarily because of internal buffering. Stripped of all processing logic, an elastic pipeline becomes a flow-through first-in-first-out memory, or FIFO. FIFOs may be clocked or event-driven; their important property is that they are elastic. I assign the name micropipeline to a particularly simple form of event-driven elastic pipeline with or without internal processing. The micro part of this name seems appropriate to me because micropipelines contain very simple circuitry, because micropipelines are useful in very short lengths, and because micropipelines are suitable for layout in microelectronic form. I have chosen micropipelines as the subject of this lecture for three reasons. First, micropipelines are simple and easy to understand. I believe that simple ideas are best, and I find beauty in the simplicity and symmetry of micropipelines. Second, I see confusion surrounding the design of FIFOs. I offer this description of micropipelines in the hope of reducing some of that confusion. The third reason I have chosen my subject addresses the limitations imposed on us by the clocked-logic conceptual framework now commonly used in the design of digital systems. I believe that this conceptual framework or mind set masks simple and useful structures like micropipelines from our thoughts, structures that are easy to design and apply given a different conceptual framework. Because micropipelines are event-driven, their simplicity is not available within the clocked-logic conceptual framework. I offer this description of micropipelines in the hope of focusing attention on an alternative transition-signalling conceptual framework. We need a new conceptual framework because the complexity of VLSI technology has now reached the point where design time and design cost often exceed fabrication time and fabrication cost. Moreover, most systems designed today are monolithic and resist mid-life improvement. The transition-signalling conceptual framework offers the opportunity to build up complex systems by hierarchical composition from simpler pieces. The resulting systems are easily modified. I believe that the transition-signalling conceptual framework has much to offer in reducing the design time and cost of complex systems and increasing their useful lifetime. I offer this description of micropipelines as an example of the transition-signalling conceptual framework. Until recently only a hardy few used the transition-signalling conceptual framework for design because it was too hard. It was nearly impossible to design the small circuits of 10 to 100 transistors that form the elemental building blocks from which complex systems are composed. Moreover, it was difficult to prove anything about the resulting compositions. In the past five years, however, much progress has been made on both fronts. Charles Molnar and his colleagues at Washington University have developed a simple way to design the small basic building blocks [9]. Martin Rem's ""VLSI Club"" at the Technical University of Eindhoven has been working effectively on the mathematics of event-driven systems [6, 10, 11, 19]. These emerging conceptual tools now make transition signalling a lively candidate for widespread use."
1989,A characterization of ten rasterization techniques.,"With widespread use of raster scan displays and the ever-increasing desire for faster interactivity, higher image complexity, and higher resolution in displayed images, several techniques have been proposed for rasterizing primitive graphical objects. This paper characterizes the performance of these techniques and shows how they evolve for more complex images on higher resolution displays. This characterization will not only show the strengths and deficiencies of existing rasterization techniques, but will also reveal new architectures for future raster graphics systems."
1983,The 8 by 8 Display.,"This paper describes a display system designed to make the recording and rearrangement of bits in a frame-buffer display system convenient and rapid. The advantage of frame-buffer displays is that because the intensity of each pixel can be specified independently, any picture can be displayed. The disadvantage is that a great many bits in the frame-buffer memory must be changed to make major changes in the picture. The 8 by 8 display described in this paper gets its name from the fact that in a single memory cycle it can access any 8 by 8 square of pixels. Internal shifters and special memory addressing circuits are provided to make the access independent of word boundaries in the memory. Pixel manipulation functions are included to process the 64 pixels thus accessed, mask them, overwrite them with new information, or combine them logically with other pixels. The resulting data can be stored into any other 8 by 8 square of pixels in a subsequent memory cycle. Looping mechanisms implemented in microcode provide RasterOp functions that transfer information from any rectangular area of the display to any other area with or without intervening pixelmodification operations. The prototype system is able to copy the entire 768 by 1024 array of the display in 52 ms, or two frame times. The ability to rearrange data quickly has proved to be an asset for character generation, line drawing, and picture construction, as well as for scrolling and other rearrangements of material already displayed on the screen. A simple model is developed to compare the performance of the 8 by 8 memory system with conventional frame-buffer organization. Execution traces of Smalltalk display programs are applied to the model to obtain figures of merit for different hardware organizations."
1981,A VLSI architecture for updating raster-scan displays.,"Interactive use of a display requires the capability to update the display rapidly. This paper describes an on-going project at Carnegie-Mellon University in which we are designing a frame buffer raster-scan display system which has the high performance typically required for interactive display applications. The system is intended to be a display for personal computers, computer generated graphic images, and image processing applications. Built using smart VLSI memory chips, the system will use parallel processing techniques to provide high performance."
1974,Reentrant Polygon Clipping.,"A new family of clipping algorithms is described. These algorithms are able to clip polygons against irregular convex plane-faced volumes in three dimensions, removing the parts of the polygon which lie outside the volume. In two dimensions the algorithms permit clipping against irregular convex windows. Polygons to be clipped are represented as an ordered sequence of vertices without repetition of first and last, in marked contrast to representation as a collection of edges as was heretofore the common procedure. Output polygons have an identical format, with new vertices introduced in sequence to describe any newly-cut edge or edges. The algorithms easily handle the particularly difficult problem of detecting that a new vertex may be required at a corner of the clipping window. The algorithms described achieve considerable simplicity by clipping separately against each clipping plane or window boundary. Code capable of clipping the polygon against a single boundary is reentered to clip against subsequent boundaries. Each such reentrant stage of clipping need store only two vertex values and may begin its processing as soon as the first output vertex from the preceeding stage is ready. Because the same code is reentered for clipping against subsequent boundaries, clipping against very complex window shapes is practical. For perspective applications in three dimensions, a six-plane truncated pyramid is chosen as the clipping volume. The two additional planes parallel to the projection screen serve to limit the range of depth preserved through the projection. A perspective projection method which provides for arbitrary view angles and depth of field in spite of simple fixed clipping planes is described. This method is ideal for subsequent hidden-surface computations."
1974,A Characterization of Ten Hidden-Surface Algorithms.,"The paper asserts that the hidden-surface problem is mainly one of sorting. The various surfaces of an object to be shown in hidden-surface or hidden-line form must be sorted to find out which ones are visible at various places on the screen. Surfaces may be sorted by lateral position in the picture (XY), by depth (Z), or by other criteria. The paper shows that the order of sorting and the types of sorting used form differences among the existing hidden-surface algorithms. (Modified author abstract)"
1974,Twinkle box: a three-dimensional computer input device.,"During the past fifteen years, use of two-dimensional computer input/output devices has become commonplace. Since the earliest uses of the light pen for target identification in air defense systems it has been obvious that two-dimensional input would be interesting and useful. A large number of two-dimensional tablets and digitizers have been developed and have come into quite effective use. These devices have made use of mechanical, electrical, magnetic, optical, and acoustic phenomena. (See bibliographical references.)"
1973,How Big Should a Printed Circuit Board Be?,"Abstract:
This correspondence outlines a theory for choosing printed circuit board dimensions in order to avoid crowding of printed wiring. Given a number of components to be mounted on the board and the dimensions of wiring, the theory predicts a minimum board size that should be easy to lay out. The theory does not tell how many components should be put on a board."
1973,Sorting and the hidden-surface problem.,"Ten years ago the task of producing hidden-surface pictures by computer seemed untractable. Courageous men pressed forward nonetheless, and today we can have quite beautiful renderings of solid objects generated by computer in remarkably short times. The pictures being produced today and the speed of the programs producing them are beyond any but the wildest dreams of ten years ago."
1969,A Method for Solving Arbitrary-Wall Mazes by Computer.,"Abstract:
A method for solving mazes with extended open areas and arbitrarily placed walls is described. This method reduces large open areas containing many possible paths to a small set of shortest paths. It is then possible to use Moore's algorithm of which the paper includes a summary. A computer simulation of a vehicle exploring an unknown maze is discussed. Crude navigation and measurement are sufficient for maze solving with the techniques described."
1969,A display processor design.,"This paper describes the results of a collaborative design effort aimed at development of a general purpose display system for the SDS-940 time-shared computer. The important features of the system evolved gradually from a number of separate design goals. We wanted a display system that would:
1. Contain an extensive but straightforward set of display generating commands.
2. Be able to generate pictures from highly complex data structures.
3. Allow easy access to display files from user programs in the main computer.
4. Provide some immediate feedback and interactive processing service to the display user, and be able to call upon the main computer for more extensive service.
5. Permit attachment of special purpose display generation and interactive hardware, as well as multiple display consoles.
6. Be capable of time-sharing its central resources among separate console-users."
1968,On the design of display processors.,"The flexibility and power needed in the channel for a computer display are considered. To work efficiently, such a channel must have a sufficient number of instruction that it is best understood as a small processor rather than a powerful channel. As it was found that successive improvements to the display processor design lie on a circular path, by making improvements one can return to the original simple design plus one new general purpose computer for each trip around. The degree of physical separation between display and parent computer is a key factor in display processor design."
1968,A futures market in computer time.,An auction method is described for allocating computer time that allows the price of computer time to fluctuate with the demand and the relative priority of users to be controlled so that more important projects get better access. This auction is free of the periodic fluctuation in computer use often associated with monthly schemes.
1968,A head-mounted three dimensional display.,"The fundamental idea behind the three-dimensional display is to present the user with a perspective image which changes as he moves. The retinal image of the real objects which we see is, after all, only two-dimensional. Thus if we can place suitable two-dimensional images on the observer's retinas, we can create the illusion that he is seeing a three-dimensional object. Although stereo presentation is important to the three-dimensional illusion, it is less important than the change that takes place in the image when the observer moves his head. The image presented by the three-dimensional display must change in exactly the way that the image of a real object would change for similar motions of the user's head. Psychologists have long known that moving perspective images appear strikingly three-dimensional even without stereo presentation; the three-dimensional display described in this paper depends heavily on this ""kinetic depth effect."""
1968,A clipping divider.,"When compared with a drawing on paper, the pictures presented by today's computer display equipment are sadly lacking in resolution. Most modern display equipment uses 10 bit digital to analog converters, providing for display in a 1024 by 1024 square raster. The actual resolution available is usually somewhat less since adjacent spots or lines will overlap. Even large-screen displays have limited resolution, for although they give a bigger picture, they also draw wider lines so that the amount of material which can appear at one time is still limited. Users of larger paper drawings have become accustomed to having a great deal of material presented at once. The computer display scope alone cannot serve the many tasks which require relatively large drawings with fine details."
1964,Sketch pad a man-machine graphical communication system.,"This paper was reproduced from the AFIPS Conference proceedings, Volume 23, of the Spring Joint Computer Conference held in Detroit, 1963. Mr. Timothy Johnson suggested that this report contained essentially the same material he spoke on at the SHARE D/A Committee Workshop."
