2019,A new golden age for computer architecture.,n/a
2019,On the Spectre and Meltdown Processor Security Vulnerabilities.,"Abstract:
This paper first reviews the Spectre and Meltdown processor security vulnerabilities that were revealed during January-October 2018 and that allow the extraction of protected information from billions of processors in large and small systems. It then discusses short-term mitigation actions and speculates on the longer term implications to computer software and hardware. This paper expands from a keynote/panel by the authors at IEEE Hot Chips 2018."
2016,"Common Bonds: MIPS, HPS, Two-Level Branch Prediction, and Compressed Code RISC Processor.","Abstract:
This column features retrospectives from the authors of six MICRO Test of Time award-winning papers: ""MIPS: A Microprocessor Architecture"" by Norman Jouppi and colleagues; ""HPS, A New Microarchitecture: Rationale and Introduction"" by Yale Patt, Wen-Mei Hwu, and Mike Shebanow; ""Critical Issues Regarding HPS, A High Performance Microarchitecture"" by Yale Patt and colleagues; ""Hardware Support for Large Atomic Units in Dynamically Scheduled Machines"" by Steve Melvin, Mike Shebanow, and Yale Patt; ""Two-Level Adaptive Training Branch Prediction"" by Tse-Yu Yeh and Yale Patt; and ""Executing Compressed Programs on an Embedded RISC Architecture"" by Andy Wolfe and Alex Chanin."
2003,"Latency, Occupancy, and Bandwidth in DSM Multiprocessors: A Performance Evaluation.","Abstract:
While the desire to use commodity parts in the communication architecture of a DSM multiprocessor offers advantages in cost and design time, the impact on application performance is unclear. We study this performance impact through detailed simulation, analytical modeling, and experiments on a flexible DSM prototype, using a range of parallel applications. We adapt the logP model to characterize the communication architectures of DSM machines. The l (network latency) and o (controller occupancy) parameters are the keys to performance in these machines, with the g (node-to-network bandwidth) parameter becoming important only for the fastest controllers. We show that, of all the logP parameters, controller occupancy has the greatest impact on application performance. Of the two contributions of occupancy to performance degradation-the latency it adds and the contention it induces-it is the contention component that governs performance regardless of network latency, showing a quadratic dependence on o. As expected, techniques to reduce the impact of latency make controller occupancy a greater bottleneck. Surprisingly, the performance impact of occupancy is substantial, even for highly-tuned applications and even in the absence of latency hiding techniques. Scaling the problem size is often used as a technique to overcome limitations in communication latency and bandwidth. Through experiments on a DSM prototype, we show that there are important classes of applications for which the performance lost by using higher occupancy controllers cannot be regained easily, if at all, by scaling the problem size."
2000,Efficient performance prediction for modern microprocessors.,"Generating an accurate estimate of the performance of a program on a given system is important to a large number of people. Computer architects, compiler writers, and developers all need insight into a machine's performance. There are a number of performance estimation techniques in use, from profile-based approaches to full machine simulation. This paper discusses a profile-based performance estimation technique that uses a lightweight instrumentation phase that runs in order number of dynamic instructions, followed by an analysis phase that runs in roughly order number of static instructions. This technique accurately predicts the performance of the core pipeline of a detailed out-of-order issue processor model while scheduling far fewer instructions than does full simulation. The difference between the predicted execution time and the time obtained from full simulation is only a few percent.
"
1999,The Future of Systems Research.,"Abstract:
After 20 years in academia and the Silicon Valley, the new Provost of Stanford University calls for a shift in focus for systems research. Performance-long the centerpiece-needs to share the spotlight with availability, maintainability, and other qualities. Although performance increases over the past 15 years have been truly amazing, it will be hard to continue these trends by sticking to the basically evolutionary path that the research community is currently on. The author advocates a more evolutionary approach to systems problems and thinks the approach needs to be more integrated. Researchers need to think about hardware and software as a continuum, not as separate parts. He sees society on the threshold of a ""post PC"" era, in which computing is ubiquitous, and everyone will use information services and everyday utilities. When everyone starts using these systems, guess what? They expect them to work and to be easy to use. So this era will drive system design toward greater availability, maintainability, and scalability, which will require a real refocusing of current research directions."
1999,A Quantitative Analysis of the Performance and Scalability of Distributed Shared Memory.,"Abstract:
Scalable cache coherence protocols have become the key technology for creating moderate to large-scale shared-memory multiprocessors. Although the performance of such multiprocessors depends critically on the performance of the cache coherence protocol, little comparative performance data is available. Existing commercial implementations use a variety of different protocols, including bit-vector/coarse-vector protocols, SCI-based protocols, and COMA protocols. Using the programmable protocol processor of the Stanford FLASH multiprocessor, we provide a detailed, implementation-oriented evaluation of four popular cache coherence protocols. In addition to measurements of the characteristics of protocol execution (e.g., memory overhead, protocol execution time, and message count) and of overall performance, we examine the effects of scaling the processor count from 1 to 128 processors. Surprisingly, the optimal protocol changes for different applications and can change with processor count even within the same application. These results help identify the strengths of specific protocols and illustrate the benefits of providing flexibility in the choice of cache coherence protocol."
1998,Retrospective: Evaluation of Directory Dchemes for Cache Coherence.,"This paper was born from work done in 1987 that aimed at exploring ways to build scalable shared-memory multiprocessors. This research began in a special graduate seminar class in Spring of 1987, which we had initiated to brainstorm on architectures for sharedmemory multiprocessors. Prior to beginning the work in this paper, we considered a variety of schemes for avoiding cache coherence. In particular, we initially explored softwarebased cache coherence schemes. We concluded that while such schemes might work well for highly structured, loop-intensive scientific applications, software-based cache coherence was too tiefficient for less structured scientific applications as well as for operating systems software. For such software environments, we concluded that either too many cache invalidations would be needed, or too much data would be need to be kept uncached. After concluding that software-based coherence would not be sufficient for a broad range of applications, we still felt that a coherence scheme that was fully general might be too expensive or hard to scale, so we began exploring a variety of schemes that significantly limited sharing. One of the first thoughts we had was to consider a scheme that allowed only a single reader for a shared writable data item. This scheme generated part of a basis for this paper, as well as for a broader exploration of directory approaches."
1998,Flexible Use of Memory for Replication/Migration in Cache-Coherent DSM Multiprocessors.,"Abstract:
Given the limitations of bus-based multiprocessors, CC-NUMA is the scalable architecture of choice for shared-memory machines. The most important characteristic of the CC-NUMA architecture is that the latency to access data on a remote node is considerably larger than the latency to access local memory. On such machines, good data locality can reduce memory stall time and is therefore a critical factor in application performance. In this paper we study the various options available to system designers to transparently decrease the fraction of data misses serviced remotely. This work is done in the context of the Stanford FLASH multiprocessor. FLASH is unique in that each node has a single pool of DRAM that can be used in a variety of ways by the programmable memory controller. We use the programmability of FLASH to explore different options for cache-coherence and data-locality in compute-server workloads. First, we consider two protocols for providing base cache-coherence, one with centralized directory information (dynamic pointer allocation) and another with distributed directory information (SCI). While several commercial systems are based on SCI, we find that a centralized scheme has superior performance. Next, we consider different hardware and software techniques that use some or all of the local memory in a node to improve data locality. Finally, we propose a hybrid scheme that combines hardware and software techniques. These schemes work on the same base platform with both user and kernel references from the workloads. The paper thus offers a realistic and fair comparison of replication/migration techniques that has not previously been feasible."
1998,An Evaluation of Directory Schemes for Cache Coherence.,"The problem of cache coherence in shared-memory multiprocessors is addressed using two basic approaches: directory schemes and snoopy cache systems. Directory schemes for cache coherence are potentially attractive in large multiprocessor systems that are beyond the scaling limits of the snoopy cache schemes. Slight modifications to directory schemes can make them competitive in performance with snoopy cache schemes for small multiprocessors. Trace-driven simulation, using data collected from several real multiprocessor applications, is used to compare the performance of standard directory schemes, modifications to these schemes, and snoopy cache protocols. In addition, the simulations show that most blocks that are written into are present in only a small number of other caches, which makes broadcast invalidates inefficient. This result suggests that a directory structure that stores with each block only a small number of pointers to caches containing the block is sufficient."
1998,Memory Consistency and Event Ordering in Scalable Shared-Memory Multiprocessors.,"A new model of memory consistency, called release consistency, that allows for more buffering and pipelining than previously proposed models is introduced. A framework for classifying shared accesses and reasoning about event ordering is developed. The release consistency model is shown to be equivalent to the sequential consistency model for parallel programs with sufficient synchronization. Possible performance gains from the less strict constraints of the release consistency model are explored. Finally, practical implementation issues are discussed, with the discussion concentrating on issues relevant to scalable architectures."
1998,The DASH Prototype: Implementation and Performance.,"The fundamental premise behind the DASH project is that it is feasible to build large-scale shared-memory multiprocessors with hardware cache coherence. While paper studies and software simulators are useful for understanding many high-level design tradeoffs, prototypes are essential to ensure that no critical details are overlooked. A prototype provides convincing evidence of the feasibility of the design, allows one to accurately estimate both the hardware and the complexity cost of various features, and provides a platform for studying real workloads. A 16-processor prototype of the DASH multiprocessor has been operational for the last six months. In this paper, the hardware overhead of directory-based cache coherence in the prototype is examined. We also discuss the performance of the system, and the speedups obtained by parallel applications running on the prototype. Using a sophisticated hardware performance monitor, we characterize the effectiveness of coherent caches and the relationship between an application's reference behavior and its speedup."
1998,The Stanford FLASH Multiprocessor.,"The FLASH multiprocessor efficiently integrates support for cache-coherent shared memory and high-performance message passing, while minimizing both hardware and software overhead. Each node in FLASH contains a microprocessor, a portion of the machine's global memory, a port to the interconnection network, The MAGIC chip handles all communication both within the node and among nodes, using hardwired data paths for efficient data movement and a programmable processor optimized for executing protocol operations. The use of the protocol processor makes FLASH very flexible/spl minus/it can support a variety of different communication mechanisms/spl minus/and simplifies the design and implementation. This paper presents the architecture of FLASH and MAGIC, and discusses the base cache-coherence and message-passing protocols. Latency and occupancy numbers, which are derived from our system-level simulator and our Verilog code, are given for several common protocol operations. The paper also describes our software strategy and FLASH's current status."
1997,A Nationwide Parallel Computing Environment.,"The National Computational Science Alliance (NCSA) hopes to accelerate the creation of a nationwide parallel computing environment for the US by developing hardware and software that will ease desktop access to the National Technology Grid. NCSA’s plans focus on experimental computer architectures, high performance user programs, machine independent analyzers for parallel computers and advanced application support that leverage parallel adaptive methods and numerical optimization. "
1997,An Evaluation of a Commercial CC-NUMA Architecture - The CONVEX Exemplar SPP1200.,"Abstract:
Studies done with academic CC-NUMA machines and simulators indicate a good potential for application performance. Our goal therefore, is to investigate whether the CONVEX Exemplar a commercial distributed shared memory machine, lives up to the expected potential of CC-NUMA machines. If not, we would like to understand what architectural or implementation decisions make it less efficient. On evaluating the delivered performance on the Exemplar we find that, while a moderate-scale Exemplar machine works well for several applications, it does not for some important classes. Further performance was affected by four fundamental characteristics of the machine, all of which are due to basic implementation and design choices made on the Exemplar. These are: the effect of processor clustering together with limited node-to-network bandwidth, the effect of tertiary caches, the limited user control over data placement, the sequential memory consistency model together with a cache-based cache coherence protocol, and lastly, longer remote latencies."
1996,SoftFLASH: Analyzing the Performance of Clustered Distributed Virtual Shared Memory.,"One potentially attractive way to build large-scale shared-memory machines is to use small-scale to medium-scale shared-memory machines as clusters that are interconnected with an off-the-shelf network. To create a shared-memory programming environment across the clusters, it is possible to use a virtual shared-memory software layer. Because of the low latency and high bandwidth of the interconnect available within each cluster, there are clear advantages in making the clusters as large as possible. The critical question then becomes whether the latency and bandwidth of the top-level network and the software system are sufficient to support the communication demands generated by the clusters.To explore these questions, we have built an aggressive kernel implementation of a virtual shared-memory system using SGI multiprocessors and 100Mbyte/sec HIPPI interconnects. The system obtains speedups on 32 processors (four nodes, eight processors per node plus additional reserved protocol processors) that range from 6.9 on the communication-intensive FFT program to 21.6 on Ocean (both from the SPLASH 2 suite). In general, clustering is effective in reducing internode miss rates, but as the cluster size increases, increases in the remote latency, mostly due to increased TLB synchronization cost, offset the advantages. For communication-intensive applications, such as FFT, the overhead of sending out network requests, the limited network bandwidth, and the long network latency prevent the achievement of good performance. Overall, this approach still appears promising, but our results indicate that large low latency networks may be needed to make cluster-based virtual shared-memory machines broadly useful as large-scale shared-memory multiprocessors.
"
1996,Application and Architectural Bottlenecks in Large Scale Distributed Shared Memory Machines.,"Many of the programming challenges encountered in small to moderate-scale hardware cache-coherent shared memory machines have been extensively studied. While work remains to be done, the basic techniques needed to efficiently program such machines have been well explored. Recently, a number of researchers have presented architectural techniques for scaling a cache coherent shared address space to much larger processor counts. In this paper, we examine the extent to which applications can achieve reasonable performance on such large-scale, cache-coherent, distributed shared address space machines, by determining the problems sizes needed to achieve a reasonable level of efficiency. We also look at how much programming effort and optimization is needed to achieve high efficiency, beyond that needed at small processor counts. For each application, we discuss the main architectural bottlenecks that prevent smaller problem sizes or less optimized programs from achieving good efficiency. Our results show that while there are some applications that either do not scale or must be heavily optimized to do so, for most of the applications we studied it is not necessary to heavily modify the code or restructure algorithms to scale well upto several hundred processors, once the basic techniques for load balancing and data locality are used that are needed for small-scale systems as well. Programs written with some care perform well without substantially compromising the ease of programming advantage of a shared address space, and the problem sizes required to achieve good performance are surprisingly small. It is important to be careful about how data structures and layouts interact with system granularities, but these optimizations are usually needed for moderate-scale machines as well.
"
1996,The computer architecture curriculum at Stanford: challenges and approaches.,n/a
1995,Effectiveness of data dependence analysis.,"Data dependence testing is the basic step in detecting loop level parallelism in numerical programs. The problem is undecidable in the general case. Therefore, work has been concentrated on a simplified problem, affine memory disambiguation. In this simpler domain, array references and loops bounds are assumed to be linear integer functions of loop variables. Dataflow information is ignored. For this domain, we have shown that in practice the problem can be solved accurately and efficiently.(1) This paper studies empirically the effectiveness of this domain restriction, how many real references are affine and flow insensitive. We use Larus's llpp system(2) to find all the data dependences dynamically. We compare these to the results given by our affine memory disambiguation system. This system is exact for all the cases we see in practice. We show that while the affine approximation is reasonable, memory disambiguation is not a sufficient approximation for data dependence analysis. We propose extensions to improve the analysis.
"
1995,"Load Balancing and Data locality in Adaptive Hierarchical N-Body Methods: Barnes-Hut, Fast Multipole, and Rasiosity.","Abstract
Hierarchical N-body methods, which are based on a fundamental insight into the nature of many physical processes, are increasingly being used to solve large-scale problems in a variety of scientific/engineering domains. Applications that use these methods are challenging to parallelize effectively, however, owing to their nonuniform, dynamically changing characteristics and their need for long-range communication. In this paper, we study the partitioning and scheduling techniques required to obtain effective parallel performance on applications that use a range of hierarchical N-body methods. To obtain representative coverage, we first examine applications that use the two best methods known for classical N-body problems: the Barnes-Hut method and the fast multipole method. Then, we examine a recent hierarchical method for radiosity calculations in computer graphics, which applies the hierarchical N-body approach to a problem with very different characteristics. We find that straightforward decomposition techniques which an automatic scheduler might implement do not scale well, because they are unable to simultaneously provide load balancing and data locality. However, all the applications yield very good parallel performance if appropriate partitioning and scheduling techniques are implemented by the programmer. For the applications that use the Barnes-Hut and fast multipole methods, simple yet effective partitioning techniques can be developed by exploiting some key insights into both the methods and the classical problems that they solve. Using a novel partitioning technique, even relatively small problems achieve 45-fold speedups on a 48-processor Stanford DASH machine (a cache-coherent, shared address space multiprocessor) and 118-fold speedups on a 128-processor simulated architecture. The very different characteristics of the radiosity application require a different partitioning/scheduling approach to be used for it; however, it too yields very good parallel performance."
1995,Implications of Hierarchical N-Body Methods for Multiprocessor Architectures.,"To design effective large-scale multiprocessors, designers need to understand the characteristics of the applications that will use the machines. Application characteristics of particular interest include the amount of communication relative to computation, the structure of the communication, and the local cache and memory requirements, as well as how these characteristics scale with larger problems and machines. One important class of applications is based on hierarchical N-body methods, which are used to solve a wide range of scientific and engineering problems efficiently. Important characteristics of these methods include the nonuniform and dynamically changing nature of the domains to which they are applied, and their use of long-range, irregular communication. This article examines the key architectural implications of representative applications that use the two dominant hierarchical N-body methods: the Barnes-Hut Method and the Fast Multipole Method.

We first show that exploiting temporal locality on accesses to communicated data is critical to obtaining good performance on these applications and then argue that coherent caches on shared-address-space machines exploit this locality both automatically and very effectively. Next, we examine the implications of scaling the applications to run on larger machines. We use scaling methods that reflect the concerns of the application scientist and find that this leads to different conclusions about how communication traffic and local cache and memory usage scale than scaling based only on data set size. In particular, we show that under the most realistic form of scaling, both the communication-to-computation ratio as well as the working-set size (and hence the ideal cache size per processor) grow slowly as larger problems are run on larger machines. Finally, we examine the effects of using the two dominant abstractions for interprocessor communication: a shared address space and explicit message passing between private address spaces. We show that the lack of an efficiently supported shared address space will substantially increase the programming complexity and performance overheads for these applications."
1995,Position Paper.,n/a
1994,COOL: An Object-Based Language for Parallel Programming.,"Abstract:
Effectively using shared-memory multiprocessors requires substantial programming effort. We present the programming language COOL (Concurrent Object-Oriented Language), which was designed to exploit coarse-grained parallelism at the task level in shared-memory multiprocessors. COOL's primary design goals are efficiency and expressiveness. By efficiency we mean that the language constructs should be efficient to implement and a program should not have to pay for features it does not use. By expressiveness, we imply that the program should flexibly support different concurrency patterns, thereby allowing various decompositions of a problem. COOL emphasizes the integration of concurrency and synchronization with data abstraction to ease the task of creating modular and efficient parallel programs. It is an extension of C++, which was chosen because it supports abstract data type definitions and is widely used.< >"
1994,SUIF: An Infrastructure for Research on Parallelizing and Optimizing Compilers.,"Compiler infrastructures that support experimental research are crucial to the advancement of high-performance computing. New compiler technology must be implemented and evaluated in the context of a complete compiler, but developing such an infrastructure requires a huge investment in time and resources. We have spent a number of years building the SUIF compiler into a powerful, flexible system, and we would now like to share the results of our efforts.SUIF consists of a small, clearly documented kernel and a toolkit of compiler passes built on top of the kernel. The kernel defines the intermediate representation, provides functions to access and manipulate the intermediate representation, and structures the interface between compiler passes. The toolkit currently includes C and Fortran front ends, a loop-level parallelism and locality optimizer, an optimizing MIPS back end, a set of compiler development tools, and support for instructional use.Although we do not expect SUIF to be suitable for everyone, we think it may be useful for many other researchers. We thus invite you to use SUIF and welcome your contributions to this infrastructure. Directions for obtaining the SUIF software are included at the end of this paper.
"
1994,False Sharing and Spatial Locality in Multiprocessor Caches.,"Abstract:
The performance of the data cache in shared-memory multiprocessors has been shown to be different from that in uniprocessors. In particular, cache miss rates in multiprocessors do not show the sharp drop typical of uniprocessors when the size of the cache block increases. The resulting high cache miss rate is a cause of concern, since it can significantly limit the performance of multiprocessors. Some researchers have speculated that this effect is due to false sharing, the coherence transactions that result when different processors update different words of the same cache block in an interleaved fashion. While the analysis of six applications in the paper confirms that false sharing has a significant impact on the miss rate, the measurements also show that poor spatial locality among accesses to shared data has an even larger impact. To mitigate false sharing and to enhance spatial locality, we optimize the layout of shared data in cache blocks in a programmer-transparent manner. We show that this approach can reduce the number of misses on shared data by about 10% on average.< >"
1994,The Performance Advantages of Integrating Block Data Trabsfer in Cache-Coherent Multiprocessors.,"Integrating support for block data transfer has become an important emphasis in recent cache-coherent shared address space multiprocessors. This paper examines the potential performance benefits of adding this support. A set of ambitious hardware mechanisms is used to study performance gains in five important scientific computations that appear to be good candidates for using block transfer. Our conclusion is that the benefits of block transfer are not substantial for hardware cache-coherent multiprocessors. The main reasons for this are (i) the relatively modest fraction of time applications spend in communication amenable to block transfer, (ii) the difficulty of finding enough independent computation to overlap with the communication latency that remains after block transfer, and (iii) long cache lines often capture many of the benefits of block transfer in efficient cache-coherent machines. In the cases where block transfer improves performance, prefetching can often provide comparable, if not superior, performance benefits. We also examine the impact of varying important communication parameters and processor speed on the effectiveness of block transfer, and comment on useful features that a block transfer facility should support for real applications.
"
1994,The Performance Impact of Flexibility in the Stanford FLASH Multiprocessor.,"A flexible communication mechanism is a desirable feature in multiprocessors because it allows support for multiple communication protocols, expands performance monitoring capabilities, and leads to a simpler design and debug process. In the Stanford FLASH multiprocessor, flexibility is obtained by requiring all transactions in a node to pass through a programmable node controller, called MAGIC. In this paper, we evaluate the performance costs of flexibility by comparing the performance of FLASH to that of an idealized hardwired machine on representative parallel applications and a multiprogramming workload. To measure the performance of FLASH, we use a detailed simulator of the FLASH and MAGIC designs, together with the code sequences that implement the cache-coherence protocol. We find that for a range of optimized parallel applications the performance differences between the idealized machine and FLASH are small. For these programs, either the miss rates are small or the latency of the programmable protocol can be hidden behind the memory access time. For applications that incur a large number of remote misses or exhibit substantial hot-spotting, performance is poor for both machines, though the increased remote access latencies or the occupancy of MAGIC lead to lower performance for the flexible design. In most cases, however, FLASH is only 2%–12% slower than the idealized machine.
"
1994,Evaluating the Memory Overhead Required for COMA Architectures.,"Abstract:
Cache only memory architectures (COMA) have an inherent memory overhead due to the organization of main memory as a large cache called an attraction memory. This overhead consists of memory left unallocated for performance reasons as well as additional physical memory required due to the cache organization of memory. The authors examine the effect of data reshuffling and data replication on the memory overhead. Data reshuffling occurs when space needs to be allocated to store a remote memory line in the local memory. Data that is reshuffled is sent between memories via replacement messages. A simple mathematical model predicts the frequency of data reshuffling as a function of the attraction memory parameters. Simulation data shows that the frequency of data reshuffling is sensitive to the allocation policy and associativity of the memory but is relatively unaffected by the block size chosen. The simulation data also shows that data replication in the attraction memory is important for good performance, but most gains can be achieved through replication in the processor caches.< >"
1994,The Stanford FLASH Multiprocessor.,"Abstract:
The FLASH multiprocessor efficiently integrates support for cache-coherent shared memory and high-performance message passing, while minimizing both hardware and software overhead. Each node in FLASH contains a microprocessor, a portion of the machine's global memory, a port to the interconnection network, The MAGIC chip handles all communication both within the node and among nodes, using hardwired data paths for efficient data movement and a programmable processor optimized for executing protocol operations. The use of the protocol processor makes FLASH very flexible/spl minus/it can support a variety of different communication mechanisms/spl minus/and simplifies the design and implementation. This paper presents the architecture of FLASH and MAGIC, and discusses the base cache-coherence and message-passing protocols. Latency and occupancy numbers, which are derived from our system-level simulator and our Verilog code, are given for several common protocol operations. The paper also describes our software strategy and FLASH's current status.< >"
1993,Scaling Parallel Programs for Multiprocessors: Methodology and Examples.,"Abstract:
Models for the constraints under which an application should be scaled, including constant problem-size scaling, memory-constrained scaling, and time-constrained scaling, are reviewed. A realistic method is described that scales all relevant parameters under considerations imposed by the application domain. This method leads to different conclusions about the effectiveness and design of large multiprocessors than the naive practice of scaling only the data set size. The primary example application is a simulation of galaxies using the Barnes-Hut hierarchical N-body method.< >"
1993,Compile-time Copy Elimination.,"Single?assignment and functional languages have value semantics that do not permit side?effects. This lack of side?effects makes automatic detection of parallelism and optimization for data locality in programs much easier. However, the same property poses a challenge in implementing these languages efficiently. This paper describes an optimizing compiler system that solves the key problem of aggregate copy elimination. The methods developed rely exclusively on compile?time algorithms, including interprocedural analysis, that are applied to an intermediate data flow representation. By dividing the problem into update?in?place and build?in?place analysis, a small set of relatively simple techniques—edge substitution, graph pattern matching, substructure sharing and substructure targeting—was found to be very powerful. If combined properly and implemented carefully, the algorithms eliminate unnecessary copy operations to a very high degree. No run?time overhead is imposed on the compiled programs.
"
1993,Mtool: An Integrated System for Performance Debugging Shared Memory Multiprocessor Applications.,"Abstract:
The authors describe Mtool, a software tool for analyzing performance losses in shared memory parallel programs. Mtool augments a program with low overhead instrumentation which perturbs the program's execution as little as possible while generating enough information to isolate memory and synchronization bottlenecks. After running the instrumented version of the parallel program, the programmer can use Mtool's window-based user interface to view compute time, memory, and synchronization objects. The authors describe Mtool's low overhead instrumentation methods, memory bottleneck detection technique, and attention focusing mechanisms, contrast Mtool with other approaches, and offer a case study to demonstrate its effectiveness.< >"
1993,The DASH Prototype: Logic Overhead and Performance.,"Abstract:
The fundamental premise behind the DASH project is that it is feasible to build large-scale shared-memory multiprocessors with hardware cache coherence. The hardware overhead of directory-based cache coherence in a 48-processor is examined. The data show that the overhead is only about 10-15%, which appears to be a small cost for the ease of programming offered by coherent caches and the potential for higher performance. The performance of the system is discussed, and the speedups obtained by a variety of parallel applications running on the prototype are shown. Using a sophisticated hardware performance monitor, the effectiveness of coherent caches and the relationship between an application's reference behavior and its speedup are characterized. The optimizations incorporated in the DASH protocol are evaluated in terms of their effectiveness on parallel applications and on atomic tests that stress the memory system.< >"
1993,Data Locality and Load Balancing in COOL.,"Hierarchical N-body methods, which are based on a fundamental insight into the nature of many physical processes, are increasingly being used to solve large-scale problems in a variety of scientific/engineering domains. Applications that use these methods are challenging to parallelize effectively, however, owing to their nonuniform, dynamically changing characteristics and their need for long-range communication. In this paper, we study the partitioning and scheduling techniques required to obtain effective parallel performance on applications that use a range of hierarchical N-body methods. To obtain representative coverage, we first examine applications that use the two best methods known for classical N-body problems: the Barnes-Hut method and the fast multipole method. Then, we examine a recent hierarchical method for radiosity calculations in computer graphics, which applies the hierarchical N-body approach to a problem with very different characteristics. We find that straightforward decomposition techniques which an automatic scheduler might implement do not scale well, because they are unable to simultaneously provide load balancing and data locality. However, all the applications yield very good parallel performance if appropriate partitioning and scheduling techniques are implemented by the programmer. For the applications that use the Barnes-Hut and fast multipole methods, simple yet effective partitioning techniques can be developed by exploiting some key insights into both the methods and the classical problems that they solve. Using a novel partitioning technique, even relatively small problems achieve 45-fold speedups on a 48-processor Stanford DASH machine (a cache-coherent, shared address space multiprocessor) and 118-fold speedups on a 128-processor simulated architecture. The very different characteristics of the radiosity application require a different partitioning/scheduling approach to be used for it; however, it too yields very good parallel performance.
"
1993,A parallel adaptive fast multipole method.,"Parallel versions of a representative N-body application that uses L. Greengard and V. Rokhlin's (1987) adaptive fast multipole method (FMM) are presented. While parallel implementations of the uniform FMM are straightforward and have been developed on different architectures, the adaptive version complicates the task of obtaining effective parallel performance owing to the nonuniform and dynamically changing nature of the problem domains to which it is applied. The authors propose and evaluate two techniques for providing load balancing and data locality, both of which take advantage of key insights into the method and its typical applications. Using the better of these techniques, they demonstrate 45-fold speedups on galactic simulations on a 48-processor Stanford DASH machine, a state-of-the-art shared address space multiprocessor, even for relatively small problems. They also show good speedups on a two-ring Kendall Square Research KSR-1. Finally, they summarize some key architectural implications of this important computational method."
1993,An empirical comparison of the Kendall Square Research KSR-1 and Stanford DASH multiprocessors.,"Two interesting variants of large-scale shared-address-space parallel architectures are cache-coherent non-uniform-memory-access machines (CC-NUMA) and cache-only memory architectures (COMA). Both have distributed main memory and use directory-based cache coherence. While both architectures migrate and replicate data at the cache level automatically under hardware control, COMA machines do this at the main memory level as well. The authors compare the parallel performance of a recent realization of each type of architecture, the Stanford DASH multiprocessor (CC-NUMA) and the Kendall Square Research KSR-1 (COMA). Using a suite of important computational kernels and complete scientific applications, they examine performance differences resulting both from the CC-NUMA/COMA nature of the machines as well as from specific differences in system implementation."
1993,The Accuracy of Trace-Driven Simulations of Multiprocessors.,"In trace-driven simulation, traces generated for one set of system characteristics are used to simulate a system with different characteristics. However, the execution path of a multiprocessor workload may depend on the order of events occurring on different processing elements. The event order, in turn, depends on system charcteristics such as memory-system latencies and buffer-sizes. Trace-driven simulations of multiprocessor workloads are inaccurate unless the dependencies are eliminated from the traces.We have measured the effects of these inaccuracies by comparing trace-driven simulations to direct simulations of the same workloads. The simulators predicted identical performance only for workloads whose traces were timing-independent. Workloads that used first-come first-served scheduling and/or non-deterministic algorithms produced timing-dependent traces, and simulation of these traces produced inaccurate performance predictions. Two types of performance metrics were particularly affected: those related to synchronization latency and those derived from relatively small numbers of events. To accurately predict such performance metrics, timing-independent traces or direct simulation should be used.
"
1992,The Stanford Dash Multiprocessor.,"Abstract:
The overall goals and major features of the directory architecture for shared memory (Dash) are presented. The fundamental premise behind the architecture is that it is possible to build a scalable high-performance machine with a single address space and coherent caches. The Dash architecture is scalable in that it achieves linear or near-linear performance growth as the number of processors increases from a few to a few thousand. This performance results from distributing the memory among processing nodes and using a network with scalable bandwidth to connect the nodes. The architecture allows shared data to be cached, significantly reducing the latency of memory accesses and yielding higher processor utilization and higher overall performance. A distributed directory-based protocol that provides cache coherence without compromising scalability is discussed in detail. The Dash prototype machine and the corresponding software support are described.< >"
1992,"Finding and Exploiting Parallelism in an Ocean Simulation Program: Experience, Results, and Implications.","Abstract
How to code and compile large application programs for execution on parallel processors is perhaps the biggest challenge facing the widespread adoption of multiprocessing. To gain insight into this problem, an ocean simulation application was converted to a parallel version. The parallel program demonstrated near-linear speed-up on an Encore Multimax, a 16-processor bus-based shared-memory machine. Parallelizing an existing sequential applicationâ€”not just a single loop or computational kernelâ€”leads to interesting insights about what issues are significant in the process of finding and implementing parallelism, and what the major challenges are. Three levels of approach to the problem of finding parallelismâ€”loop-level parallelization, program restructuring, and algorithm modificationâ€”were attempted, with widely varying results. Loop-level parallelization did not scale sufficiently. High-level restructuring was useful for much of the application, but obtaining an efficient parallel program required algorithm changes to one portion of it. Implementation issues for scalable performance, such as data locality and synchronization, are also discussed. The nature, requirements, and success of the various transformations lend insight into the design of parallelizing tools and parallel programming environments."
1992,Programming for Different Memory Consistency Models.,"Abstract
The memory consistency model, or memory model, supported by a shared-memory multiprocessor directly affects its performance. The most commonly assumed memory model is sequential consistency (SC). While SC provides a simple model for the programmer, it imposes rigid constraints on the ordering of memory accesses and restricts the use of common hardware and compiler optimizations. To remedy the shortcomings of SC, several relaxed memory models have been proposed in the literature. These include processor consistency (PC), weak ordering (WO), release consistency (RCsc/RCpc), total store ordering (TSO), and partial store ordering (PSO). While the relaxed models provide the potential for higher performance, they present a more complex model for programmers when compared to SC. Our previous research has addressed this tradeoff by taking a programmer-centric approach. We have proposed memory models (DRF0, DRF1, PL) that allow the programmer to reason with SC, but require certain information about the memory accesses. This information is used by the system to relax the ordering among memory accesses while still maintaining SC for the programmer. Our previous models formalized the information that allowed optimizations associated with WO and RCsc to be used. This paper extends the above approach by defining a new model, PLpc, that allows optimizations of the TSO, PSO, PC, and RCpc models as well. Thus, PLpc provides a unified programming model that maintains the ease of reasoning with SC while providing for efficiency and portability across a wide range of proposed system designs."
1992,Characterizing the Caching and Synchronization Performance of a Multiprocessor Operating System.,"Good cache memory performance is essential to achieving high CPU utilization in shared-memory multiprocessors. While the performance of caches is determined by both application end operating system (OS ) references, most research has focused on the cache performance of applications afone. This is partiafly due to the difficulty of measuring OS activity and as a resrtl~ the cache performance of the OS is largely unknown. In this paper, we characterize the cache performance of a commercial System V UNIX rtrttrtittg on a four-CPU multiprocessor. The related issue of the performance impact of the OS synchronization activity is tdso stttdicd. For our study, we use a hardware monitor that records the cache misses in the machine without perturbing it. We study three multiprocessor workloads: a parallel Compilq a multiprogrsmmed load and a commercial database. Our results show that OS misses occur frequently enough to stall CPUS for 17-21 ‘Yoof their non-idle time. Further, if we include application misses induced by OS interference in the cache, then the SQU time reaches 25%. A detailed analysis reveals three major sources of OS misses: instruction fetehea, process migratiom and data accesses in block operations. As for synchronization behavior, we find that OS syncfrrordzation has low overhead if supported correctly end that OS locks show good locality and low contention."
1992,Hiding Memory Latency using Dynamic Scheduling in Shared-Memory Multiprocessors.,"The large latency of memory accesses is a major impediment to achieving high performance in large scale shared-memory multi-processsors. Relaxing the memory consistency model is an attractive technique for hiding this latency by allowing the overlap of memory accesses with other computation and memory accesses. Previous studies on relaxed models have shown that the latency of write accesses can be hidden by buffering writes and allowing reads to bypass pending writes. Hiding the latency of reads by exploiting the overlap allowed by relaxed models is inherently more difficult, however, simply because the processor depends on the return value for its future computation.

This paper explores the use of dynamically scheduled processors to exploit the overlap allowed by relaxed models for hiding the latency of reads. Our results are based on detailed simulation studies of several parallel applications. The results show that a substantial fraction of the read latency can be hidden using this technique. However, the major improvements in performance are achieved only at large instruction window sizes."
1992,The DASH Prototype: Implementation and Performance.,"The fundamental premise behind the DASH project is that it is feasible to build large-scale shared-memory multiprocessors with hardware cache coherence. While paper studies and software simulators are useful for understanding many high-level design trade-offs, prototypes are essential to ensure that no critical details are overlooked. A prototype provides convincing evidence of the feasibility of the design allows one to accurately estimate both the hardware and the complexity cost of various features, and provides a platform for studying real workloads. A 16-processor prototype of the DASH multiprocessor has been operational for the last six months. In this paper, the hardware overhead of directory-based cache coherence in the prototype is examined. We also discuss the performance of the system, and the speedups obtained by parallel applications running on the prototype. Using a sophisticated hardware performance monitor, we characterize the effectiveness of coherent caches and the relationship between an application's reference behavior and its speedup.
"
1992,Sharlit - A Tool for Building Optimizers.,"A complex and time-consuming function of a modern compiler is global optimization. Unlike other functions of a compiler such as parsing and code generation which examine only one statement or one basic block at a time, optimizers are much larger in scope, examining and changing large portions of a program all at once. The larger scope means optimizers must perform many program transformations. Each of these transformations makes its own particular demands on the internal representation of programs; each can interact with and depend on the others in different ways. This makes optimizers large and complex.

Despite their complexity, few tools exist to help in building optimizers. This is in stark contrast with other parts of the compiler where years of experience have culminated in tools with which these other parts can be constructed easily. For example, parser generators are used to build front-ends, and peephole optimizers and tree matchers are used to build code generators.

This paper presents Sharlit, a tool to support the construction of modular and extensible global optimizers. We will show how Sharlit helps in constructing data-flow analyzers and the transformations that use data-flow analysis information, both are major components of any optimizer.

Sharlit is implemented in C++ and uses C++ in the same way that YACC uses C. Thus we assume the reader has some familiarity with C++[9]."
1991,Computer Technology and Architecture: An Evolving Interaction.,"Abstract:
The interaction between computer architecture and IC technology is examined. To evaluate the attractiveness of particular technologies, computer designs are assessed primarily on the basis of performance and cost. The focus is mainly on CPU performance, both because it is easier to measure and because the impact of technology is most easily seen in the CPU. The technology trends discussed concern memory size, design complexity and time, and design scaling. Architectural trends in the areas of pipelining, memory systems, and multiprocessing are considered. Opportunities and problems to be solved in the years ahead are identified.< >"
1991,Performance Evaluation of Memory Consistency Models for Shared Memory Multiprocessors.,"The memory consistency model supported by a multiprocessor architecture determines the amount of buffering and pipelining that may be used to hide or reduce the latency of memory accesses. Several different consistency models have been proposed. These range from sequential consistency on one end, allowing very limited buffering, to release consistency on the other end, allowing extensive buffering and pipelining. The processor consistency and weak consistency models fall in between. The advantage of the less strict models is increased performance potential. The disadvantage is increased hardware complexity and a more complex programming model. To make an informed decision on the above tradeoff requires performance data for the various models. This paper addresses the issue of performance benefits from the above four consistency models. Our results are based on simulation studies done for three applications. The results show that in an environment where processor reads are blocking and writes are buffered, a significant performance increase is achieved from allowing reads to bypass previous writes. Pipelining of writes, which determines the rate at which writes are retired from the write buffer, is of secondary importance. As a result, we show that the sequential consistency model performs poorly relative to all other models, while the processor consistency model provides most of the benefits of the weak and release consistency models."
1991,Multiprocessor Simulation and Tracing Using Tango.,"Tango is a software simulation and tracing system used to obtain data for evaluating parallel programs and multiprocessor systems. The system provides a simulated multiprocessor environment by multiplexing application processes onto a single processor. The user application is compiled into a simulation system that is customized to meet the accuracy and efficiency requirements for a particular set of experiments. Tango supports trace-driven simulation, but users also have the option of using execution-driven simulation. Unlike trace-driven simulation, execution-driven simulation ensures accurate ordering of program events and permits accurate simulation of contention and process interactions. Tango avoids costly instruction interpretation and emulation by directly executing user application code whenever possible. Simulation time is also greatly reduced by allowing the user to focus on the program operations of primary interest, such as shared data references or synchronization operations. The system is currently being used in a wide range of investigations, from algorithm studies to detailed hardware evaluations."
1991,MTOOL: A Method for Isolating Memory Bottlenecks in Shared Memory Multiprocessor Programs.,"This paper presents a new, relatively inexpensive method for detecting regions (e.g. loops and procedures) in a program where the memory hierarchy is performing poorly. By observing where actual measured execution time differs from the time predicted given a perfect memory system, we can isolate memory bottlenecks. MTOOL, an implementation of the approach aimed at applications programs running on MIPS-chip based workstations is described and results for some of the Perfect Club and SPEC benchmarks are summarized."
1991,Two Techniques to Enhance the Performance of Memory Consistency Models.,"The memory consistency model supported by a multiprocessor directly affects its performance. Thus, several attempts have been made to relax the consistency models to allow for more buffering and pipelining of memory accesses. Unfortunately, the potential increase in performance afforded by relaxing the consistency model is accompanied by a more complex programming model. This paper introduces two general implementation techniques that provide higher performance for all the models. The first technique involves prefetching values for accesses that are delayed due to consistency model constraints. The second technique employs speculative execution to allow the processor to proceed even though the consistency model requires the memory accesses to be delayed. When combined, the above techniques alleviate the limitations imposed by a consistency model on buffering and pipelining of memory accesses, thus significantly reducing the impact of the memory consistency model on performance."
1991,Comparative Evaluation of Latency Reducing and Tolerating Techniques.,"Techniques that can cope with the large latency of memory accesses are essential for achieving high processor utilization in large-scale shared-memory multiprocessors. In this paper, we consider four architectural techniques that address the latency problem: (i) hardware coherent caches, (ii) relaxed memory consistency, (iii) softwarecontrolled prefetching, and (iv) multiple-context support. While some studies of benefits of the individual techniques have been done, no study evaluates all of the techniques within a consistent framework. This paper attempts to remedy this by providing a comprehensive evaluation of the benefits of the four techniques, both individually and in combinations, using a consistent set of architectural assumptions. The results in this paper have been obtained using detailed simulations of a large-scale shared-memory multiprocessor. Our results show that caches and relaxed consistency uniformly improve performance. The improvements due to prefetching and multiple contexts are sizeable, but are much more applicationdependent. Combinations of the various techniques generally attain better performance than each one on its own. Overall, we show that using suitable combinations of the techniques, performance can be improved by 4 to 7 times."
1991,Integrating Scalar Optimization and Parallelization.,"Abstract
Compiling programs to use parallelism and memory hierarchy efficiently requires both parallelizing (high-level) transformations and traditional scalar (low-level) optimizations. Our compiler has only one intermediate language â€” SUIF (Stanford University Intermediate Form) â€” for both parallelization and scalar optimizations. Having only one intermediate language offers two advantages: no duplication of functions between the two levels, and availability of high-level information at the low-level. This paper shows how SUIF integrates the two levels of abstraction, and how the SUIF compiler is organized to take advantage of this integration."
1991,Efficient and Exact Data Dependence Analysis.,"Data dependence testing is the basic step in detecting loop level parallelism in numerieal programs. The problem is equivalent to integer linear programming and thus in general cannot be solved efficiently. Current methods in use employ inexact methods that sacrifice potential parallelism in order to improve compiler efficiency. This paper shows that in practice, data dependence can be computed exactly and efficiently. There are three major ideas that lead to this result. First, we have developed and assembled a small set of efficient algorithms, each one exact for special case inputs. Combined with a moderately expensive backup test, they are exact for all the cases we have seen in practice. Second, we introduce a memorization technique to save results of previous tests, thus avoiding calling the data dependence routines multiple times on the same input. Third, we show that this approach can both be extended to compute distance and direction vectors and to use unknowns ymbolic terms without any loss of accuracy or efficiency, We have implemented our algorithm in the SUIF system, a general purpose compiler system developwl at Stanford. We ran the algorithm on the PERFECT Club Benchmarks and our data dependence analyzer gave an exact solution in all cases efficiently,"
1991,Performance debugging shared memory multiprocessor programs with MTOOL.,"This paper describes MTOOL, a sofware tool for analyzing performance losses in shared memory parallel programs. MTOOL augments a program with low overhead instrumentatwn which perturbs the program’s execution as little as possible while generating enough irylormation to isolate memory and synchronization bottlenecks. After running the instrumented version of the parallel program, the programmer can use MTOOL’S window-based user interface to view memory, synchronization, and compute time bottlenecks at increasing levels of detailfrom a whole program level down to the level of individual procedures, loops and synchrordzation objects. An initial implementation of MTOOL runs on Silicon Graphics multiprocessors and is in use by several groups at Stanford."
1991,MTOOL: A Method for Detecting Memory Bottlenecks.,"This paper presents a new, relatively inexpensive method for detecting regions (e.g. loops and procedures) in a program where the memory hierarchy is performing poorly. By observing where actual measured execution time differs from the time predicted given a perfect memory system, we can isolate memory bottlenecks. MTOOL, an implementation of the approach aimed at applications programs running on MIPS-chip based workstations is described and results for some of the Perfect Club and SPEC benchmarks are summarized.
"
1990,A Spectral Lower Bound Techniqye for the Size of Decision Trees and Two Level AND/OR Circuits.,"Abstract:
A universal lower-bound technique for the size and other implementation characteristics of an arbitrary Boolean function as a decision tree and as a two-level AND/OR circuit is derived. The technique is based on the power spectrum coefficients of the n dimensional Fourier transform of the function. The bounds vary from constant to exponential and are tight in many cases. Several examples are presented.< >"
1990,The Priority-Based Coloring Approach to Register Allocation.,"Global register allocation plays a major role in determining the efficacy of an optimizing compiler. Graph coloring has been used as the central paradigm for register allocation in modern compilers. A straightforward coloring approach can suffer from several shortcomings. These shortcomings are addressed in this paper by coloring the graph using a priority ordering. A natural method for dealing with the spilling emerges from this approach. The detailed algorithms for a priority-based coloring approach are presented and are contrasted with the basic graph-coloring algorithm. Various extensions to the basic algorithms are also presented. Measurements of large programs are used to determine the effectiveness of the algorithm and its extensions, as well as the causes of an imperfect allocation. Running time of the allocator and the impact of heuristics aimed at reducing that time are also measured.
"
1990,Design of scalable shared-memory multiprocessors: the DASH approach.,"Abstract:
The DASH (directory architecture for shared-memory) multiprocessor, which combines the programmability of shared-memory machines with the scalability of message-passing machines, is described. Hardware-supported coherent caches provide for low-latency access of shared data and ease of programming. Caches are kept coherent by means of a distributed directory-based protocol. Shared memory in the machine is distributed among the processing nodes, and scalable memory bandwidth is provided by connecting the nodes through a general interconnection network. The prototype DASH machine will consists of 64 high-performance microprocessors, with an aggregate performance of over 1200 MIPS and 250 scalar MFLOPS. The fundamental premise in DASH is that it is possible to build a scalable shared-memory machine with hardware-supported coherent caches by using a distributed directory-based cache coherence protocol. The mechanisms for providing scalable memory bandwidth, reducing and tolerating memory latency, and supporting efficient synchronization are described. A brief description of the machine's implementation is given.<>"
1990,Estimating the Performance Advantages of Relaxing Consistency in a Shared Memory Multiprocessor.,n/a
1990,Share Data Placement Optimizations to Reduce Multiprocessor Cache Miss Rates.,n/a
1990,Memory Consistency and Event Ordering in Scalable Shared-Memory Multiprocessors.,"A new model of memory consistency, called release consistency, that allows for more buffering and pipelining than previously proposed models is introduced. A framework for classifying shared accesses and reasoning about event ordering is developed. The release consistency model is shown to be equivalent to the sequential consistency model for parallel programs with sufficient synchronization. Possible performance gains from the less strict constraints of the release consistency model are explored. Finally, practical implementation issues are discussed, with the discussion concentrating on issues relevant to scalable architectures."
1990,The Directory-Based Cache Coherence Protocol for the DASH Multiprocessor.,"DASH is a scalable shared-memory multiprocessor currently being developed at Stanford's Computer Systems Laboratory. The architecture consists of powerful processing nodes, each with a portion of the shared-memory, connected to a scalable interconnection network. A key feature of DASH is its distributed directory-based cache coherence protocol. Unlike traditional snoopy coherence protocols, the DASH protocol does not rely on broadcast; instead it uses point-to-point messages sent between the processors and memories to keep caches consistent. Furthermore, the DASH system does not contain any single serialization or control point. While these features provide the basis for scalability, they also force a reevaluation of many fundamental issues involved in the design of a protocol. These include the issues of correctness, performance and protocol complexity. In this paper, we present the design of the DASH coherence protocol and discuss how it addresses the above issues. We also discuss our strategy for verifying the correctness of the protocol and briefly compare our protocol to the IEEE Scalable Coherent Interface protocol.
"
1990,Analysis of Critical Architectural and Program Parameters in a Hierarchical Shared Memory Multiprocessor.,"Scalable shared-memory multiprocessors are the subject of much current research, but little is known about the performance behavior of these machines. This paper studies the performance effects of two machine characteristics and two program characteristics that seem to be major factors in determining the performance of a hierarchical shared-memory machine. We develop an analytical model of the traffic in a machine loosely based on Stanford's DASH multiprocessor and use program parameters extracted from multiprocessor traces to study its performance. It is shown that both locality in the data reference stream and the amount of data sharing in a program have an important impact on performance. Although less obvious, the bandwidth within each cluster in the hierarchy also has a significant performance effect. Optimizations that improve the intracluster cache coherence protocol or increase the bandwidth within a cluster can be quite effective.
"
1989,An Analytical Cache Model.,"Trace-driven simulation and hardware measurement are the techniques most often used to obtain accurate performance figures for caches. The former requires a large amount of simulation time to evaluate each cache configuration while the latter is restricted to measurements of existing caches. An analytical cache model that uses parameters extracted from address traces of programs can efficiently provide estimates of cache performance and show the effects of varying cache parameters. By representing the factors that affect cache performance, we develop an analytical model that gives miss rates for a given trace as a function of cache size, degree of associativity, block size, subblock size, multiprogramming level, task switch interval, and observation interval. The predicted values closely approximate the results of trace-driven simulations, while requiring only a small fraction of the computation cost.
"
1989,A Simple Interprocedural Register Allocation Algorithm and Its Effectiveness for Lisp.,"Register allocation is an important optimization in many compilers, but with per-procedure register allocation, it is often not possible to make good use of a large register set. Procedure calls limit the improvement from global register allocation, since they force variables allocated to registers to be saved and restored. This limitation is more pronounced in LISP programs due to the higher frequency of procedure calls. An interprocedural register allocation algorithm is developed by simplifying a version of interprocedural graph coloring. The simplification corresponds to a bottom-up coloring of the interference graph. The scheme is evaluated using a number of LISP programs. The evaluation considers the scheme's limitations and compares these “software register windows” against the hardware register windows used in the Berkeley RISC and SPUR processors.
"
1989,Characteristics of Performance-Optimal Multi-Level Cache Hierarchies.,"The increasing speed of new generation processors will exacerbate the already large difference between CPU cycle times and main memory access times. As this difference grows, it will be increasingly difficult to build single-level caches that are both fast enough to match these fast cycle times and large enough to effectively hide the slow main memory access times. One solution to this problem is to use a multi-level cache hierarchy. This paper examines the relationship between cache organization and program execution time for multi-level caches. We show that a first-level cache dramatically reduces the number of references seen by a second-level cache, without having a large effect on the number of second-level cache misses. This reduction in the number of second-level cache hits changes the optimal design point by decreasing the importance of the cycle-time of the second-level cache relative to its size. The lower the first-level cache miss rate, the less important the second-level cycle time becomes. This change in relative importance of cycle time and miss rate makes associativity more attractive and increases the optimal cache size for second-level caches over what they would be for an equivalent single-level cache system.
"
1989,Copy Elimination in Functional Languages.,"Copy elimination is an important optimization for compiling functional languages. Copies arise because these languages lack the concepts of state and variable; hence updating an object involves a copy in a naive implementation. Copies are also possible if proper targeting has not been carried out inside functions and across function calls. Targeting is the proper selection of a storage area for evaluating an expression. By abstracting a collection of functions by a target operator, we compute targets of function bodies that can then be used to define an optimized interpreter to eliminate copies due to updates and copies across function calls. The language we consider is typed lambda calculus with higher-order functions and special constructs for array operations. Our approach can eliminate copies in divide and conquer problems like quicksort and bitonic sort that previous approaches could not handle.

We also present some results of implementing a compiler for a single assignment language called SAL on some small but tough programs. Our results indicate that it is possible to approach a performance comparable to imperative languages like Pascal."
1988,Lisp on a Reduced-Instruction-Set Processor: Characterization and Optimization.,"Abstract:
The factors that motivated the choice of a reduced-instruction-set computer (RISC) on which to implement Lisp are examined. Dynamic profiling measurements used to characterise Lisp are reported. The implementation of tags in Lisp and the cost of function calls are discussed. Interprocedural register allocation is examined. Execution results for various benchmarks are presented and discussed.< >"
1988,Measurement and Evaluation of the MIPS Architecture and Processor.,"MIPS is a 32-bit processor architecture that has been implemented as an nMOS VLSI chip. The instruction set architecture is RISC-based. Close coupling with compilers and efficient use of the instruction set by compiled programs were goals of the architecture. The MIPS architecture requires that the software implement some constraints in the design that are normally considered part of the hardware implementation. This paper presents experimental results on the effectiveness of this processor as a program host. Using sets of large and small benchmarks, the instruction and operand usage patterns are examined both for optimized and unoptimized code. Several of the architectural and organizational innovations in MIPS, including software pipeline scheduling, multiple-operation instructions, and word-based addressing, are examined in light of this data.
"
1988,Cache Performance of Operating System and Multiprogramming Workloads.,"Large caches are necessary in current high-performance computer systems to provide the required high memory bandwidth. Because a small decrease in cache performance can result in significant system performance degradation, accurately characterizing the performance of large caches is important. Although measurements on actual systems have shown that operating systems and multiprogramming can affect cache performance, previous studies have not focused on these effects. We have developed a program tracing technique called ATUM (Address Tracing Using Microcode) that captures realistic traces of multitasking workloads including the operating system. Examining cache behavior using these traces from a VAX processor shows that both the operating system and multiprogramming activity significantly degrade cache performance, with an even greater proportional impact on large caches. From a careful analysis of the causes of this degradation, we explore various techniques to reduce this loss. While seemingly little can be done to mitigate the effect of system references, multitasking cache miss activity can be substantially reduced with small hardware additions.
"
1988,An Evaluation of Directory Schemes for Cache Coherence.,"Abstract:
The problem of cache coherence in shared-memory multiprocessors is addressed using two basic approaches: directory schemes and snoopy cache systems. Directory schemes for cache coherence are potentially attractive in large multiprocessor systems that are beyond the scaling limits of the snoopy cache schemes. Slight modifications to directory schemes can make them competitive in performance with snoopy cache schemes for small multiprocessors. Trace-driven simulation, using data collected from several real multiprocessor applications, is used to compare the performance of standard directory schemes, modifications to these schemes, and snoopy cache protocols. In addition, the simulations show that most blocks that are written into are present in only a small number of other caches, which makes broadcast invalidates inefficient. This result suggests that a directory structure that stores with each block only a small number of pointers to caches containing the block is sufficient.< >"
1988,Performance Tradeoffs in Cache Design.,"Abstract:
A series of simulations that explore the interactions between various organizational decisions and program execution time are presented. The tradeoffs between cache size and CPU/cache cycle-time, set associativity and cycle time, and block size and main-memory speed, are investigated. The results indicate that neither cycle time nor cache size dominates the other across the entire design space. For common implementation technologies, performance is maximized when the size is increased to the size is increased to the 32-kB to 128-kB range with modest penalties to the cycle time. If set associativity impacts the cycle time by more than a few nanoseconds, it increases overall execution time. Since the block size and memory-transfer rate combine to affect the cache miss penalty, the optimum block size is substantially smaller than that which minimizes the miss rate. The interdependence between optimal cache configuration and the main memory speed necessitates multilevel cache hierarchies for high-performance uniprocessors.< >"
1988,A Simple and Efficient Implementation Approach for Single Assignment Languages.,"Functional and single assignment languages have semantically pure features that do not permit side effects. This lack of side effects makes detection of parallelism in programs much easier. However, the same property poses a challenge in implementing these languages efficiently. A preliminary implementation of a compiler for the single assignment language, SISAL, is described. The compiler uses reference counts for memory management and copy avoidance. Performance results on a wide range of benchmark programs show that SISAL programs compiled by our implementation run 2-3 times slower on average than the same programs written in C, Pascal, and Fortran, and orders of magnitude faster than other implementations of single assignment languages. Extensions of these techniques for multiprocessor implementations are proposed."
1988,Characterizing the Synchronization Behavior of Parallel Programs.,"Contention for synchronization locks and delays waiting for synchronization events can substantially increase the running time of a parallel program. This makes it important to characterize the synchronization behavior of programs and to provide analysis tools to aid both the hardware and software designer in evaluating design alternatives. This paper describes a tracing facility that is incorporated into a synchronization package. This facility provides a portable means to accurately and efficiently characterize parallel programs. The behavior of several applications has been monitored uncovering program characteristics that make it difficult to achieve linear speedup. Our monitoring facility allows a programmer to determine the performance implications of the synchronization structure he has used, and it allows the architect to evaluate various hardware support mechanisms."
1987,Tags and Type Checking in Lisp: Hardware and Software Approaches.,"One of the major factors that distinguishes LISP from many other languages (Pascal, C, Fortran, etc.) is the need for run-time type checking. Run-time type checking is implemented by adding to each data object a tag that encodes type information. Tags must be compared for type compatibility, removed when using the data, and inserted when new data items are created. This tag manipulation, together with other work related to dynamic type checking and generic operations, constitutes a significant component of the execution time of LISP programs. This has led both to the development of LISP machines that support tag checking in hardware and to the avoidance of type checking by users running on stock hardware. To understand the role and necessity of special-purpose hardware for tag handling, we first measure the cost of type checking operations for a group of LISP programs. We then examine hardware and software implementations of tag operations and estimate the cost of tag handling with the different tag implementation schemes. The data shows that minimal levels of support provide most of the benefits, and that tag operations can be relatively inexpensive, even when no special hardware support is present."
1986,Reducing the Cost of Branches.,"Pipelining is the major organizational technique that computers use to reach higher single-processor performance. A fundamental disadvantage of pipelining is the loss incurred due to branches that require stalling or flushing the pipeline. Both hardware solutions and architectural changes have been proposed to overcome these problems. This paper examines a range of schemes for reducing branch cost focusing on both static (compile-time) and dynamic (hardware-assisted) prediction of branches. These schemes are investigated from quantitative performance and implementation viewpoints.1
"
1986,LISP on a Reduced-Instruction-Set-Processor.,The factors that motivated the choice of a reduced-instruction-set computer (RISC) on which to implement Lisp are examined. Dynamic profiling measurements used to characterise Lisp are reported. The implementation of tags in Lisp and the cost of function calls are discussed. Interprocedural register allocation is examined. Execution results for various benchmarks are presented and discussed.< >
1986,Partitioning Parallel Programs for Macro-Dataflow.,Partitioning techniques are necessary to execute functional programs at a coarse granularity. Fine-granularity execution is inefficient on general-purpose multiprocessors. There is a trade-off between parallelism and the overhead of exploiting parallelism. A compile-time partitioning approach to achieve this trade-off is presented. 
1986,Compile-time partitioning and scheduling of parallel programs.,"Partitioning and scheduling techniques are necessary to implement parallel languages on multiprocessors. Multiprocessor performance is maximized when parallelism between tasks is optimally traded off with communication and synchronization overhead. We present compile-time partitioning and scheduling techniques to achieve this trade-off.
"
1985,SWAMI: a flexible logic implementation system.,"A new system for logic synthesis and VLSI layout, the Stanford Weinberger Array Minimizer and Implementor (SWAMI), has been developed. This paper describes the system's algorithms and presents preliminary results. The minimization of logic expressions uses local sum-of-products minimization, kernel factorization and common subexpression recognition and generates improved expressions of arbitrary depth. Logic expressions are realized in nMOS technology using one dimensional Weinberger array structures or a new extension of Weinberger arrays to two dimensions. The placement phase uses heuristic techniques, including simulated annealing. MIN-CUT linear arrangement and local constructive clustering.
"
1984,VLSI Processor Architecture.,"Abstract:
A processor architecture attempts to compromise between the needs of programs hosted on the architecture and the performance attainable in implementing the architecture. The needs of programs are most accurately reflected by the dynamic use of the instruction set as the target for a high level language compiler. In VLSI, the issue of implementation of an instruction set architecture is significant in determining the features of the architecture. Recent processor architectures have focused on two major trends: large microcoded instruction sets and simplified, or reduced, instruction sets. The attractiveness of these two approaches is affected by the choice of a single-chip implementation. The two different styles require different tradeoffs to attain an implementation in silicon with a reasonable area. The two styles consume the chip area for different purposes, thus achieving performance by different strategies. In a VLSI implementation of an architecture, many problems can arise from the base technology and its limitations. Although circuit design techniques can help alleviate many of these problems, the architects must be aware of these limitations and understand their implications at the instruction set level."
1984,Register allocation by priority-based coloring.,"The classic problem of global register allocation is treated in a heuristic and practical manner by adopting the notion of priorities in node-coloring. The assignment of priorities is based on estimates of the benefits that can be derived from allocating individual quantities in registers. Using the priorities, the exponential coloring process can be made to run in linear time. Since the costs involved in register allocation are taken into account, the algorithm does not over-allocate. The algorithm can be parameterized to cater to different fetch characteristics and register configurations among machines. Measurements indicate that the register allocation scheme is effective on a number of target machines. The results confirm that, using priority-based coloring, global register allocation can be performed practically and efficiently.
"
1983,Postpass Code Optimization of Pipeline Constraints.,"Pipeline interlocks are used in a pipelined architecture to prevent the execution of a machine instruction before its operands are available. An alternative to this complex piece of hardware is to rearrange the instructions at compile time to avoid pipeline interlocks. This problem is called code reorganization and is studied. The basic problem of reorganization of machine-level instructions at compile time is shown to be np-complete. A heuristic algorithm is proposed, and its properties and effectiveness are explored. Empirical data from MIPs, a VLSI processor design, are given. The impact of code reorganization techniques on the rest of a compiler system is discussed. 30 references."
1982,Retargetable Compiler Code Generation.,"A classification of automated retargetable code generation techniques and a survey of the work on these techniques is presented. Retargetable code generation research is classified into three categories: interpretive code generation, pattern-matched code generation, and table-driven code generation. Interpretive code generation approaches generate code for a virtual machine and then expand into real target code. Pattern-matched code generation approaches separate the machine description from the code generation algorithm. Table-driven code generation approaches employ a formal machine description and use a code-generator generator to produce code generators automatically. An analysis of these techniques and a critique of automatic code generation algorithms are presented."
1982,The Design and Implementation of Parametric Types in Pascal.,"Parametric types offer an attractive solution to the problems of dealing with arrays in Pascal. These problems arise from the use of strong, static type checking, especially of array?type procedure arguments. Parametric types provide solutions both for the array procedure argument problem and allow the consistent inclusion of arrays with dynamic bounds. A parametric type mechanism is proposed and design issues are discussed. The inclusion of parametric types has major effects on the implementation of a language like Pascal. The implementation issues and implementation versus design tradeoffs are examined. The implementation strategy used can be extended to accommodate the standard and generic types in Ada.
"
1982,Compilation of the Pascal Case Statement.,"Pascal case statements can be compiled using a variety of methods, including comparison trees and branch tables. The scheme discussed here combines the two techniques to allow comparison trees with entries that are branch tables. The use of a combination of the two techniques is shown to adapt well to certain instances of case statements. Extensions to the standard case statement also require such a scheme to obtain an efficient implementation.
"
1982,Symbolic Debugging of Optimized Code.,The long standing conflict between the optimization of code and the ability to symbolically debug the code is examined. The effects of local and global optimizations on the variables of a program are categorized and models for representing the effect of optimizations are given. These models are used by algorithms which determine the subset of variables whose values do not correspond to those in the original program. Algorithms for restoring these variables to their correct values are also developed. Empirical results from the application of these algorithms to local optimization are presented.
1982,Hardware/Software Tradeoffs for Increased Performance.,"Most new computer architectures are concerned with maximizing performance by providing suitable instruction sets for compiled code and providing support for systems functions. We argue that the most effective design methodology must make simultaneous tradeoffs across all three areas: hardware, software support, and systems support. Recent trends lean towards extensive hardware support for both the compiler and operating systems software. However, consideration of all possible design tradeoffs may often lead to less hardware support. Several examples of this approach are presented, including: omission of condition codes, word-addressed machines, and imposing pipeline interlocks in software. The specifics and performance of these approaches are examined with respect to the MIPS processor.
"
1982,The MIPS Machine.,n/a
1982,MIPS: A microprocessor architecture.,"MIPS is a new single chip VLSI microprocessor. It attempts to achieve high performance with the use of a simplified instruction set, similar to those found in microengines. The processor is a fast pipelined engine without pipeline interlocks. Software solutions to several traditional hardware problems, such as providing pipeline interlocks, are used.
"
1982,Optimizing delayed branches.,"Delayed branches are commonly found in micro-architectures. A compiler or assembler can exploit delayed branches. This is achieved by moving code from one of several points to the positions following the branch instruction. We present several strategies for moving code to utilize the branch delay, and discuss the requirements and benefits of these strategies. An algorithm for processing branch delays has been implemented and we give empirical results. The performance data show that a reasonable percentage of these delays can be avoided.
"
1982,Code Generation and Reorganization in the Presence of Pipeline Constraints.,"Pipeline interlocks are used in a pipelined architecture to prevent the execution of a machine instruction before its operands are available. An alternative to this complex piece of hardware is to rearrange the instructions at compile-time to avoid pipeline interlocks. This problem, called code reorganization, is studied. The basic problem of reorganization of machine level instructions at compile-time is shown to be NP-complete. A heuristic algorithm is proposed and its properties and effectiveness are explored. The impact of code reorganization techniques on the rest of a compiler system are discussed."
1981,The Formal Definition of a Real-Time Language.,"This paper presents the formal definition of TOMAL (Task-Oriented Microprocessor Applications Language), a programming language intended for real-time systems running on small processors. The formal definition addresses all aspects of the language. Because some modes of semantic definition seem particularly well-suited to certain aspects of a language, and not as suitable for others, the formal definition employs several complementary modes of definition.

The primary definition is axiomatic and is employed to define most statements of the language. Simple, denotational (but not lattice-theoretic) semantics complement the axiomatic semantics to define type-related features, such as binding of names to types, data type coercions, and evaluation of expressions. Together, the axiomatic and denotational semantics define all features of the sequential language. An operational definition is used to define real-time execution, and to extend the axiomatic definition to account for all aspects of concurrent execution. Semantic constraints, sufficient to guarantee conformity of a program with the axiomatic definition, can be checked by analysis of a TOMAL program at compilation."
1981,Program Optimization and Exception Handling.,"Optimization of programs that may contain exception handling facilities requires new techniques. Program optimizations that do not account for exception handling facilities may incorrectly transform a procedure that can raise an exception, producing different results from the unoptimized version. Restricted exception handling mechanisms that allow optimization are discussed. Data flow equations for determining the effects of exception handling are presented.
"
1981,WSClock - A Simple and Effective Algorithm for Virtual Memory Management.,"A new virtual memory management algorithm WSCLOCK has been synthesized from the local working set (WS) algorithm, the global CLOCK algorithm, and a new load control mechanism for auxiliary memory access. The new algorithm combines the most useful feature of WS—a natural and effective load control that prevents thrashing—with the simplicity and efficiency of CLOCK. Studies are presented to show that the performance of WS and WSCLOCK are equivalent, even if the savings in overhead are ignored.
"
1980,Parallelism and Representation Problems in Distributed Systems.,"Abstract:
A hierarchical view of program representation is used to explain the problems of matching various representations to underlying distributed architectures. If a program is to effectively use a distributed computer system, it is necessary to represent and detect a high degree of parallelism. Methods of detecting such parallelism and their limitations are discussed. The actual machine level representation of a high-level language program also affects the ability to achieve a good match between the computer system resources and the program. The concept of an ideal machine for the program leads naturally to a representation employing a directly executed language. The initial program representation profoundly influences the possibility of obtaining a good representation at other levels of the hierarchy. A poor initial language representation leads to unnecessary architectural contraints or insufficient information to efficiently execute a program. The issue of suitable initial representation for distributed hardware is approached employing a functional language basis."
1980,An Interactive Graphics System for custom design.,"The Interactive Graphics System/370 (IGS/370) is one of a series of highly interactive programs 1,2 used extensively within IBM for the design of multiplanar chips, macros, modules, cards, and boards. The programs were developed for IBM's internal use and are not marketed by IBM.

This paper describes the hardware and system software environment and the design functions, capacity and performance of IGS/370.

The geometric descriptions and associated attributes defining the LSI devices are entered by a beam-directed refresh cathode ray tube, a digitizer, or a graphics interface language. Many capabilities exist for the creation and modification of all phases of design. Data library items called cells, consisting of rectangles, lines, polygons, circles, alphanumerics, attributes and references to other cells, are created, edited and manipulated into a final design. These final designs, output in the graphics interface language, then become source data for the checking and post-processing programs which result in the manufactured product."
